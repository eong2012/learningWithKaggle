{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from datetime import datetime\n",
    "import distutils.dir_util\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Input, Lambda, BatchNormalization, Conv2D, Dropout\n",
    "from keras.layers import ZeroPadding2D, MaxPooling2D, AveragePooling2D, Activation, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "from keras import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3276 images belonging to 8 classes.\n",
      "Found 500 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get data for visualisation later\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# def preprocess_input(x, data_format=None):\n",
    "#     \"\"\"Preprocesses a tensor encoding a batch of images.\n",
    "#     # Arguments\n",
    "#         x: input Numpy tensor, 4D.\n",
    "#         data_format: data format of the image tensor.\n",
    "#     # Returns\n",
    "#         Preprocessed tensor.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 'RGB'->'BGR'\n",
    "#     x = x[:, :, ::-1]\n",
    "#     # Zero-center by mean pixel\n",
    "#     x[:, :, 0] -= 103.939\n",
    "#     x[:, :, 1] -= 116.779\n",
    "#     x[:, :, 2] -= 123.68\n",
    "#     return x\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/fishing/train',\n",
    "        target_size=(360, 640),\n",
    "        batch_size=28,\n",
    "        #batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/fishing/valid',\n",
    "        target_size=(360, 640),\n",
    "        shuffle=False,\n",
    "        #batch_size=batch_size,\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/fishing/test_stg1',\n",
    "        target_size=(360, 640),\n",
    "        shuffle=False,\n",
    "        #batch_size=batch_size,\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_precomputed_data(model, batches):\n",
    "    filenames = batches.filenames\n",
    "    conv_features = model.predict_generator(batches, (batches.samples/batches.batch_size ), verbose=1)\n",
    "    labels_onehot = to_categorical(batches.classes)\n",
    "    labels = batches.classes\n",
    "    return (filenames, conv_features, labels_onehot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 302s   \n",
      "50/50 [==============================] - 55s    \n",
      "50/50 [==============================] - 110s   \n"
     ]
    }
   ],
   "source": [
    "trn_filenames, trn_conv_features, trn_labels, trn_labels_1 = create_precomputed_data(base_model, train_generator)\n",
    "val_filenames, val_conv_features, val_labels, val_labels_1 = create_precomputed_data(base_model, validation_generator)\n",
    "test_filenames, test_conv_features, test_labels, test_labels_1 = create_precomputed_data(base_model, test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/ubuntu/data/fishing/results'\n",
    "\n",
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_precomputed_data(filenames, conv_feats, labels, features_base_name=\"VGG16_640_conv_feats/trn_\"):\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat', np.array(filenames))\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat', conv_feats)\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat', np.array(labels))\n",
    "    \n",
    "save_precomputed_data(trn_filenames, trn_conv_features, trn_labels, \"VGG16_640_conv_feats/trn_\")\n",
    "save_precomputed_data(val_filenames, val_conv_features, val_labels, \"VGG16_640_conv_feats/val_\")\n",
    "save_precomputed_data(test_filenames, test_conv_features, test_labels, \"VGG16_640_conv_feats/test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_precomputed_data(features_base_name=\"VGG16_640_conv_feats/trn_\"):\n",
    "    filenames = load_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat').tolist()\n",
    "    conv_feats = load_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat')\n",
    "    labels = load_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat')\n",
    "    return filenames, conv_feats, labels\n",
    "\n",
    "trn_filenames, trn_conv_features, trn_labels = load_precomputed_data(\"VGG16_640_conv_feats/trn_\")\n",
    "val_filenames, val_conv_features, val_labels = load_precomputed_data(\"VGG16_640_conv_feats/val_\")\n",
    "test_filenames, test_conv_features, test_labels = load_precomputed_data(\"VGG16_640_conv_feats/test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
