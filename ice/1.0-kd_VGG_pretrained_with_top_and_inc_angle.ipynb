{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/ubuntu/data/iceberg'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "import keras\n",
    "import os\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.merge import Add, Concatenate\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "from scipy.misc import imresize\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "\n",
    "        # Rescale\n",
    "#         a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "#         b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "#         c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "#         imgs.append(np.dstack((a, b, c)))\n",
    "#         imgs.append(np.dstack((band_1, band_2, band_3)))\n",
    "#         img_orig = Image.fromarray(np.dstack((band_1, band_2, band_3)), 'RGB')\n",
    "#         img = img_orig.resize((224, 224), img_orig)\n",
    "        img = resize(np.dstack((band_1, band_2, band_3)), (224, 224), mode='constant')\n",
    "        imgs.append(img)\n",
    "\n",
    "    return np.array(imgs)\n",
    "\n",
    "def get_more_images(imgs):\n",
    "    \n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "      \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        a=imgs[i,:,:,0]\n",
    "        b=imgs[i,:,:,1]\n",
    "        c=imgs[i,:,:,2]\n",
    "        \n",
    "        av=cv2.flip(a,1)\n",
    "        ah=cv2.flip(a,0)\n",
    "        bv=cv2.flip(b,1)\n",
    "        bh=cv2.flip(b,0)\n",
    "        cv=cv2.flip(c,1)\n",
    "        ch=cv2.flip(c,0)\n",
    "        \n",
    "        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n",
    "        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n",
    "      \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "       \n",
    "    more_images = np.concatenate((imgs,v,h))\n",
    "    \n",
    "    return more_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(os.path.join(data_dir, 'train.json'))\n",
    "Xtrain = get_scaled_imgs(df_train)\n",
    "Ytrain = np.array(df_train['is_iceberg'])\n",
    "\n",
    "df_train.inc_angle = df_train.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(df_train.inc_angle>0)\n",
    "\n",
    "Ytrain = Ytrain[idx_tr[0]]\n",
    "Xtrain = Xtrain[idx_tr[0],...]\n",
    "Xinc = df_train.inc_angle[idx_tr[0]]\n",
    "\n",
    "# remove all 3 below if you just want orginal data\n",
    "Xtrain = get_more_images(Xtrain)\n",
    "Xinc = np.concatenate((Xinc,Xinc,Xinc))\n",
    "Ytrain = np.concatenate((Ytrain,Ytrain,Ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4413, 224, 224, 3), (4413,), (4413,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xinc.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split data for validation - bit of an arbitary split here\n",
    "\n",
    "Xvalid = Xtrain[0:700]\n",
    "Xinc_valid = Xinc[0:700]\n",
    "Yvalid = Ytrain[0:700]\n",
    "\n",
    "Xtrain_train = Xtrain[700:4413]\n",
    "Xinc_train = Xinc[700:4413]\n",
    "Ytrain_train = Ytrain[700:4413]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3713, 224, 224, 3), (3713,), (3713,), (700, 224, 224, 3), (700,), (700,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_train.shape, Xinc_train.shape, Ytrain_train.shape, Xvalid.shape, Xinc_valid.shape, Yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_precomputed_data(model, data, data_labels):\n",
    "    conv_features = model.predict(data)\n",
    "    labels_onehot = to_categorical(data_labels)\n",
    "    labels = data_labels\n",
    "    return (conv_features, labels_onehot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn_conv_features, trn_labels, trn_labels_1 = create_precomputed_data(vgg_base, Xtrain_train, Ytrain_train)\n",
    "# val_conv_features, val_labels, val_labels_1 = create_precomputed_data(vgg_base, Xvalid, Yvalid)\n",
    "all_conv_features, all_labels, all_labels_1 = create_precomputed_data(vgg_base, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3713, 7, 7, 512), (3713, 2), (700, 7, 7, 512), (700, 2))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_conv_features.shape, trn_labels.shape, val_conv_features.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert trn_conv_features.shape == (3713, 7, 7, 512), \"trn_conv_features not as expected\"\n",
    "assert trn_labels.shape == (3713, 2), \"trn_labels not as expected\"\n",
    "\n",
    "assert val_conv_features.shape == (700, 7, 7, 512), \"val_conv_features not as expected\"\n",
    "assert val_labels.shape == (700, 2), \"val_labels not as expected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/ubuntu/data/iceberg/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_precomputed_data(conv_feats, labels, inc_angle, features_base_name=\"VGG16_conv_feats_aug/trn_\"):\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat', conv_feats)\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat', np.array(labels))\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'inc_angle_feats.dat', conv_feats)\n",
    "    \n",
    "save_precomputed_data(trn_conv_features, trn_labels, Xinc_train, \"VGG16_conv_feats_aug/trn_\")\n",
    "save_precomputed_data(val_conv_features, val_labels, Xinc_valid, \"VGG16_conv_feats_aug/val_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_precomputed_data(features_base_name=\"VGG16_conv_feats_aug/trn_\"):\n",
    "    conv_feats = load_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat')\n",
    "    labels = load_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat')\n",
    "    return conv_feats, labels\n",
    "\n",
    "trn_conv_features, trn_labels = load_precomputed_data(\"VGG16_conv_feats_aug/trn_\")\n",
    "val_conv_features, val_labels = load_precomputed_data(\"VGG16_conv_feats_aug/val_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = 0.3 \n",
    "\n",
    "classifier_input_shape = (7, 7, 512)\n",
    "classifier_input = Input(shape=classifier_input_shape)\n",
    "\n",
    "x= Flatten()(classifier_input)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(256, activation='sigmoid')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "                                                     \n",
    "classifier_model_v1 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v1.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir='/home/ubuntu/data/iceberg/tb_logs_ice/', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3713 samples, validate on 700 samples\n",
      "Epoch 1/50\n",
      "3713/3713 [==============================] - 3s 805us/step - loss: 0.7241 - acc: 0.5834 - val_loss: 0.5659 - val_acc: 0.6786\n",
      "Epoch 2/50\n",
      "3713/3713 [==============================] - 3s 674us/step - loss: 0.4996 - acc: 0.7460 - val_loss: 0.3908 - val_acc: 0.8243\n",
      "Epoch 3/50\n",
      "3713/3713 [==============================] - 3s 674us/step - loss: 0.4012 - acc: 0.8093 - val_loss: 0.4526 - val_acc: 0.7714\n",
      "Epoch 4/50\n",
      "3713/3713 [==============================] - 2s 673us/step - loss: 0.3660 - acc: 0.8263 - val_loss: 0.4607 - val_acc: 0.8057\n",
      "Epoch 5/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.3265 - acc: 0.8519 - val_loss: 0.3271 - val_acc: 0.8529\n",
      "Epoch 6/50\n",
      "3713/3713 [==============================] - 2s 670us/step - loss: 0.2832 - acc: 0.8745 - val_loss: 0.3140 - val_acc: 0.8671\n",
      "Epoch 7/50\n",
      "3713/3713 [==============================] - 3s 679us/step - loss: 0.2585 - acc: 0.8898 - val_loss: 0.3199 - val_acc: 0.8557\n",
      "Epoch 8/50\n",
      "3713/3713 [==============================] - 3s 677us/step - loss: 0.2364 - acc: 0.8993 - val_loss: 0.3107 - val_acc: 0.8629\n",
      "Epoch 9/50\n",
      "3713/3713 [==============================] - 3s 678us/step - loss: 0.2035 - acc: 0.9125 - val_loss: 0.3525 - val_acc: 0.8657\n",
      "Epoch 10/50\n",
      "3713/3713 [==============================] - 3s 680us/step - loss: 0.2074 - acc: 0.9106 - val_loss: 0.3413 - val_acc: 0.8614\n",
      "Epoch 11/50\n",
      "3713/3713 [==============================] - 3s 679us/step - loss: 0.2063 - acc: 0.9200 - val_loss: 0.3381 - val_acc: 0.8443\n",
      "Epoch 12/50\n",
      "3713/3713 [==============================] - 2s 668us/step - loss: 0.1952 - acc: 0.9187 - val_loss: 0.3686 - val_acc: 0.8729\n",
      "Epoch 13/50\n",
      "3713/3713 [==============================] - 2s 668us/step - loss: 0.1639 - acc: 0.9324 - val_loss: 0.3596 - val_acc: 0.8829\n",
      "Epoch 14/50\n",
      "3713/3713 [==============================] - 2s 670us/step - loss: 0.1411 - acc: 0.9391 - val_loss: 0.7211 - val_acc: 0.7757\n",
      "Epoch 15/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1402 - acc: 0.9434 - val_loss: 0.4597 - val_acc: 0.8471\n",
      "Epoch 16/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1331 - acc: 0.9486 - val_loss: 0.4055 - val_acc: 0.8729\n",
      "Epoch 17/50\n",
      "3713/3713 [==============================] - 3s 674us/step - loss: 0.1066 - acc: 0.9539 - val_loss: 0.4565 - val_acc: 0.8729\n",
      "Epoch 18/50\n",
      "3713/3713 [==============================] - 2s 672us/step - loss: 0.1225 - acc: 0.9464 - val_loss: 0.3986 - val_acc: 0.8786\n",
      "Epoch 19/50\n",
      "3713/3713 [==============================] - 2s 670us/step - loss: 0.1024 - acc: 0.9604 - val_loss: 0.5698 - val_acc: 0.8543\n",
      "Epoch 20/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1296 - acc: 0.9483 - val_loss: 0.3275 - val_acc: 0.8729\n",
      "Epoch 21/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1336 - acc: 0.9453 - val_loss: 0.3722 - val_acc: 0.8757\n",
      "Epoch 22/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1102 - acc: 0.9577 - val_loss: 0.4400 - val_acc: 0.8714\n",
      "Epoch 23/50\n",
      "3713/3713 [==============================] - 2s 670us/step - loss: 0.0700 - acc: 0.9739 - val_loss: 0.5516 - val_acc: 0.8529\n",
      "Epoch 24/50\n",
      "3713/3713 [==============================] - 2s 672us/step - loss: 0.1100 - acc: 0.9580 - val_loss: 0.4164 - val_acc: 0.8686\n",
      "Epoch 25/50\n",
      "3713/3713 [==============================] - 2s 669us/step - loss: 0.0918 - acc: 0.9653 - val_loss: 0.4000 - val_acc: 0.8543\n",
      "Epoch 26/50\n",
      "3713/3713 [==============================] - 2s 669us/step - loss: 0.0946 - acc: 0.9626 - val_loss: 0.4377 - val_acc: 0.8771\n",
      "Epoch 27/50\n",
      "3713/3713 [==============================] - 3s 686us/step - loss: 0.0857 - acc: 0.9663 - val_loss: 0.4101 - val_acc: 0.8786\n",
      "Epoch 28/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.0770 - acc: 0.9682 - val_loss: 0.3831 - val_acc: 0.8600\n",
      "Epoch 29/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1273 - acc: 0.9469 - val_loss: 0.5726 - val_acc: 0.8500\n",
      "Epoch 30/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.0807 - acc: 0.9634 - val_loss: 0.5211 - val_acc: 0.8586\n",
      "Epoch 31/50\n",
      "3713/3713 [==============================] - 3s 675us/step - loss: 0.0772 - acc: 0.9674 - val_loss: 0.5514 - val_acc: 0.8800\n",
      "Epoch 32/50\n",
      "3713/3713 [==============================] - 2s 668us/step - loss: 0.1100 - acc: 0.9521 - val_loss: 0.3597 - val_acc: 0.8643\n",
      "Epoch 33/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1858 - acc: 0.9135 - val_loss: 0.4237 - val_acc: 0.8686\n",
      "Epoch 34/50\n",
      "3713/3713 [==============================] - 2s 673us/step - loss: 0.1594 - acc: 0.9238 - val_loss: 0.4250 - val_acc: 0.8614\n",
      "Epoch 35/50\n",
      "3713/3713 [==============================] - 2s 672us/step - loss: 0.1143 - acc: 0.9437 - val_loss: 0.3859 - val_acc: 0.8600\n",
      "Epoch 36/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.0860 - acc: 0.9601 - val_loss: 0.6587 - val_acc: 0.8529\n",
      "Epoch 37/50\n",
      "3713/3713 [==============================] - 3s 680us/step - loss: 0.1212 - acc: 0.9510 - val_loss: 0.4036 - val_acc: 0.8329\n",
      "Epoch 38/50\n",
      "3713/3713 [==============================] - 3s 687us/step - loss: 0.1155 - acc: 0.9513 - val_loss: 0.4668 - val_acc: 0.8700\n",
      "Epoch 39/50\n",
      "3713/3713 [==============================] - 3s 690us/step - loss: 0.0755 - acc: 0.9671 - val_loss: 0.4715 - val_acc: 0.8671\n",
      "Epoch 40/50\n",
      "3713/3713 [==============================] - 3s 679us/step - loss: 0.1253 - acc: 0.9437 - val_loss: 0.4999 - val_acc: 0.8757\n",
      "Epoch 41/50\n",
      "3713/3713 [==============================] - 3s 680us/step - loss: 0.0976 - acc: 0.9539 - val_loss: 0.5620 - val_acc: 0.8743\n",
      "Epoch 42/50\n",
      "3713/3713 [==============================] - 3s 683us/step - loss: 0.1151 - acc: 0.9504 - val_loss: 0.4048 - val_acc: 0.8586\n",
      "Epoch 43/50\n",
      "3713/3713 [==============================] - 3s 675us/step - loss: 0.0971 - acc: 0.9599 - val_loss: 0.4245 - val_acc: 0.8729\n",
      "Epoch 44/50\n",
      "3713/3713 [==============================] - 3s 675us/step - loss: 0.1283 - acc: 0.9397 - val_loss: 0.4550 - val_acc: 0.8643\n",
      "Epoch 45/50\n",
      "3713/3713 [==============================] - 2s 669us/step - loss: 0.0833 - acc: 0.9639 - val_loss: 0.4622 - val_acc: 0.8557\n",
      "Epoch 46/50\n",
      "3713/3713 [==============================] - 2s 673us/step - loss: 0.0950 - acc: 0.9580 - val_loss: 0.4010 - val_acc: 0.8700\n",
      "Epoch 47/50\n",
      "3713/3713 [==============================] - 2s 671us/step - loss: 0.1127 - acc: 0.9469 - val_loss: 0.6572 - val_acc: 0.8571\n",
      "Epoch 48/50\n",
      "3713/3713 [==============================] - 2s 672us/step - loss: 0.1242 - acc: 0.9507 - val_loss: 0.4702 - val_acc: 0.8657\n",
      "Epoch 49/50\n",
      "3713/3713 [==============================] - 2s 673us/step - loss: 0.1032 - acc: 0.9507 - val_loss: 0.4340 - val_acc: 0.8671\n",
      "Epoch 50/50\n",
      "3713/3713 [==============================] - 2s 670us/step - loss: 0.0738 - acc: 0.9677 - val_loss: 0.4963 - val_acc: 0.8729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd885539c18>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v1.fit(trn_conv_features, trn_labels,\n",
    "                                          batch_size=32, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeper model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf = 128\n",
    "p = 0.2 # adding any dropout at all means it doesnt train at all\n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='sigmoid', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "\n",
    "# x = MaxPooling2D((1,2))(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v2 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v2.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3713 samples, validate on 700 samples\n",
      "Epoch 1/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.5290 - acc: 0.7576 - val_loss: 0.4810 - val_acc: 0.7657\n",
      "Epoch 2/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.3236 - acc: 0.8605 - val_loss: 0.3179 - val_acc: 0.8571\n",
      "Epoch 3/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2610 - acc: 0.8901 - val_loss: 0.3771 - val_acc: 0.8429\n",
      "Epoch 4/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2058 - acc: 0.9127 - val_loss: 0.6927 - val_acc: 0.7843\n",
      "Epoch 5/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1615 - acc: 0.9372 - val_loss: 0.3214 - val_acc: 0.8743\n",
      "Epoch 6/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1283 - acc: 0.9461 - val_loss: 0.3556 - val_acc: 0.8743\n",
      "Epoch 7/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0866 - acc: 0.9685 - val_loss: 0.3779 - val_acc: 0.8657\n",
      "Epoch 8/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0692 - acc: 0.9688 - val_loss: 0.5819 - val_acc: 0.8757\n",
      "Epoch 9/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0546 - acc: 0.9809 - val_loss: 0.4701 - val_acc: 0.8857\n",
      "Epoch 10/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0532 - acc: 0.9774 - val_loss: 0.4982 - val_acc: 0.8857\n",
      "Epoch 11/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0429 - acc: 0.9817 - val_loss: 0.4147 - val_acc: 0.8986\n",
      "Epoch 12/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0291 - acc: 0.9890 - val_loss: 0.5604 - val_acc: 0.8771\n",
      "Epoch 13/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0286 - acc: 0.9892 - val_loss: 0.6399 - val_acc: 0.8514\n",
      "Epoch 14/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0247 - acc: 0.9908 - val_loss: 0.7178 - val_acc: 0.8743\n",
      "Epoch 15/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0349 - acc: 0.9879 - val_loss: 0.4959 - val_acc: 0.8671\n",
      "Epoch 16/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1067 - acc: 0.9591 - val_loss: 0.6911 - val_acc: 0.8686\n",
      "Epoch 17/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0418 - acc: 0.9860 - val_loss: 0.6305 - val_acc: 0.8571\n",
      "Epoch 18/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0283 - acc: 0.9906 - val_loss: 0.5513 - val_acc: 0.8757\n",
      "Epoch 19/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0335 - acc: 0.9879 - val_loss: 1.4953 - val_acc: 0.6543\n",
      "Epoch 20/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0211 - acc: 0.9914 - val_loss: 0.6148 - val_acc: 0.8786\n",
      "Epoch 21/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.9540 - val_acc: 0.8557\n",
      "Epoch 22/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.5980 - val_acc: 0.8757\n",
      "Epoch 23/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0198 - acc: 0.9919 - val_loss: 0.4324 - val_acc: 0.8871\n",
      "Epoch 24/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0072 - acc: 0.9973 - val_loss: 0.4988 - val_acc: 0.8871\n",
      "Epoch 25/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0037 - acc: 0.9984 - val_loss: 0.5834 - val_acc: 0.9014\n",
      "Epoch 26/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.4965 - val_acc: 0.8886\n",
      "Epoch 27/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0188 - acc: 0.9933 - val_loss: 0.5332 - val_acc: 0.9000\n",
      "Epoch 28/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 0.8498 - val_acc: 0.8743\n",
      "Epoch 29/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.7230 - val_acc: 0.8900\n",
      "Epoch 30/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0047 - acc: 0.9978 - val_loss: 0.7493 - val_acc: 0.8686\n",
      "Epoch 31/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.6446 - val_acc: 0.8857\n",
      "Epoch 32/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.5494 - val_acc: 0.9014\n",
      "Epoch 33/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0157 - acc: 0.9943 - val_loss: 0.7376 - val_acc: 0.8871\n",
      "Epoch 34/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.9283 - val_acc: 0.8686\n",
      "Epoch 35/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.6073 - val_acc: 0.8814\n",
      "Epoch 36/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0109 - acc: 0.9960 - val_loss: 0.6029 - val_acc: 0.8786\n",
      "Epoch 37/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.6079 - val_acc: 0.8857\n",
      "Epoch 38/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.6168 - val_acc: 0.8900\n",
      "Epoch 39/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.6864e-04 - acc: 1.0000 - val_loss: 0.6456 - val_acc: 0.8914\n",
      "Epoch 40/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.5778e-04 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.8957\n",
      "Epoch 41/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 9.3471e-05 - acc: 1.0000 - val_loss: 0.7523 - val_acc: 0.8971\n",
      "Epoch 42/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 3.6324e-05 - acc: 1.0000 - val_loss: 0.7973 - val_acc: 0.8929\n",
      "Epoch 43/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 7.3407e-05 - acc: 1.0000 - val_loss: 0.7747 - val_acc: 0.8957\n",
      "Epoch 44/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.2697e-05 - acc: 1.0000 - val_loss: 0.7853 - val_acc: 0.8971\n",
      "Epoch 45/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.3919e-05 - acc: 1.0000 - val_loss: 0.7963 - val_acc: 0.8957\n",
      "Epoch 46/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.6570e-05 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.9000\n",
      "Epoch 47/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.0648e-05 - acc: 1.0000 - val_loss: 0.8175 - val_acc: 0.8957\n",
      "Epoch 48/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 6.1210e-06 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.8957\n",
      "Epoch 49/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 7.7222e-06 - acc: 1.0000 - val_loss: 0.8267 - val_acc: 0.8957\n",
      "Epoch 50/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.2025e-06 - acc: 1.0000 - val_loss: 0.8382 - val_acc: 0.8971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd852b7b6a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v2.fit(trn_conv_features, trn_labels,\n",
    "                                          batch_size=32, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 128\n",
    "p = 0. # adding any dropout at all means it doesnt train at all\n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "\n",
    "# x = MaxPooling2D((1,2))(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v3 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v3.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3713 samples, validate on 700 samples\n",
      "Epoch 1/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.5313 - acc: 0.7498 - val_loss: 0.7826 - val_acc: 0.6957\n",
      "Epoch 2/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.3282 - acc: 0.8529 - val_loss: 0.4505 - val_acc: 0.8071\n",
      "Epoch 3/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2591 - acc: 0.8942 - val_loss: 0.2983 - val_acc: 0.8800\n",
      "Epoch 4/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2205 - acc: 0.9076 - val_loss: 0.4919 - val_acc: 0.7986\n",
      "Epoch 5/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1512 - acc: 0.9405 - val_loss: 1.0548 - val_acc: 0.6986\n",
      "Epoch 6/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1279 - acc: 0.9534 - val_loss: 0.4099 - val_acc: 0.8771\n",
      "Epoch 7/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0948 - acc: 0.9623 - val_loss: 0.4143 - val_acc: 0.8600\n",
      "Epoch 8/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0838 - acc: 0.9671 - val_loss: 0.4132 - val_acc: 0.8800\n",
      "Epoch 9/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0540 - acc: 0.9795 - val_loss: 0.7802 - val_acc: 0.8643\n",
      "Epoch 10/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0546 - acc: 0.9785 - val_loss: 0.5321 - val_acc: 0.8729\n",
      "Epoch 11/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0154 - acc: 0.9954 - val_loss: 1.3157 - val_acc: 0.8143\n",
      "Epoch 12/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0936 - acc: 0.9674 - val_loss: 0.6855 - val_acc: 0.8614\n",
      "Epoch 13/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0479 - acc: 0.9838 - val_loss: 0.9705 - val_acc: 0.8186\n",
      "Epoch 14/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0359 - acc: 0.9873 - val_loss: 0.6472 - val_acc: 0.8814\n",
      "Epoch 15/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0299 - acc: 0.9887 - val_loss: 0.6495 - val_acc: 0.8800\n",
      "Epoch 16/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0317 - acc: 0.9908 - val_loss: 0.5112 - val_acc: 0.8957\n",
      "Epoch 17/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.5241 - val_acc: 0.8957\n",
      "Epoch 18/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0213 - acc: 0.9919 - val_loss: 0.5665 - val_acc: 0.8843\n",
      "Epoch 19/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0181 - acc: 0.9933 - val_loss: 0.8141 - val_acc: 0.8671\n",
      "Epoch 20/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0573 - acc: 0.9801 - val_loss: 0.6226 - val_acc: 0.8814\n",
      "Epoch 21/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.5343 - val_acc: 0.8914\n",
      "Epoch 22/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0096 - acc: 0.9965 - val_loss: 0.7504 - val_acc: 0.8814\n",
      "Epoch 23/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.5994 - val_acc: 0.8929\n",
      "Epoch 24/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.6699 - val_acc: 0.8829\n",
      "Epoch 25/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.7441 - val_acc: 0.8800\n",
      "Epoch 26/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0170 - acc: 0.9941 - val_loss: 0.5970 - val_acc: 0.8914\n",
      "Epoch 27/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0165 - acc: 0.9941 - val_loss: 0.6681 - val_acc: 0.8986\n",
      "Epoch 28/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0068 - acc: 0.9976 - val_loss: 0.6618 - val_acc: 0.8886\n",
      "Epoch 29/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0057 - acc: 0.9976 - val_loss: 0.7167 - val_acc: 0.8871\n",
      "Epoch 30/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.7419 - val_acc: 0.8857\n",
      "Epoch 31/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 7.8741e-04 - acc: 0.9997 - val_loss: 0.7739 - val_acc: 0.8914\n",
      "Epoch 32/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 7.9480e-05 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.8943\n",
      "Epoch 33/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 9.1780e-05 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.8971\n",
      "Epoch 34/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.2102e-05 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.8957\n",
      "Epoch 35/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 4.7919e-05 - acc: 1.0000 - val_loss: 0.7970 - val_acc: 0.8971\n",
      "Epoch 36/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 5.5956e-05 - acc: 1.0000 - val_loss: 0.8126 - val_acc: 0.8929\n",
      "Epoch 37/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.7287e-04 - acc: 1.0000 - val_loss: 0.8079 - val_acc: 0.8929\n",
      "Epoch 38/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.8593e-05 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.8929\n",
      "Epoch 39/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.6776e-05 - acc: 1.0000 - val_loss: 0.8314 - val_acc: 0.8943\n",
      "Epoch 40/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.5798e-05 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.8957\n",
      "Epoch 41/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.4754e-05 - acc: 1.0000 - val_loss: 0.8389 - val_acc: 0.8957\n",
      "Epoch 42/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.7643e-05 - acc: 1.0000 - val_loss: 0.8478 - val_acc: 0.8957\n",
      "Epoch 43/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.4231e-05 - acc: 1.0000 - val_loss: 0.8498 - val_acc: 0.8957\n",
      "Epoch 44/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.0325e-05 - acc: 1.0000 - val_loss: 0.8527 - val_acc: 0.8957\n",
      "Epoch 45/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.2961e-06 - acc: 1.0000 - val_loss: 0.8613 - val_acc: 0.8957\n",
      "Epoch 46/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.0050e-05 - acc: 1.0000 - val_loss: 0.8663 - val_acc: 0.8957\n",
      "Epoch 47/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.5784e-06 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.8957\n",
      "Epoch 48/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 7.6087e-06 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.8957\n",
      "Epoch 49/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 8.3367e-06 - acc: 1.0000 - val_loss: 0.8754 - val_acc: 0.8943\n",
      "Epoch 50/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 6.7168e-06 - acc: 1.0000 - val_loss: 0.8789 - val_acc: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd83ff31978>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v3.fit(trn_conv_features, trn_labels,\n",
    "                                          batch_size=32, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeper model with inc angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_angle_input = Input(shape=(1,))\n",
    "\n",
    "nf = 128\n",
    "p = 0.2 \n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "\n",
    "# x = MaxPooling2D((1,2))(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Activation('softmax')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "m = Concatenate()([inc_angle_input, x])\n",
    "m = Dense(512, activation='relu')(m)\n",
    "m = Dense(256, activation='relu')(m)\n",
    "out = Dense(2, activation='sigmoid')(m)\n",
    "# out = Activation('softmax')(m)\n",
    "\n",
    "optimizer = Adam(lr=0.001, decay=0.0)\n",
    "model_inc_angle = Model(inputs=[classifier_input, inc_angle_input], outputs=out)\n",
    "model_inc_angle.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3713 samples, validate on 700 samples\n",
      "Epoch 1/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.5566 - acc: 0.7106 - val_loss: 2.3891 - val_acc: 0.5071\n",
      "Epoch 2/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.4129 - acc: 0.8139 - val_loss: 0.3530 - val_acc: 0.8479\n",
      "Epoch 3/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.3411 - acc: 0.8519 - val_loss: 0.3392 - val_acc: 0.8529\n",
      "Epoch 4/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2604 - acc: 0.8892 - val_loss: 0.3031 - val_acc: 0.8764\n",
      "Epoch 5/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.2404 - acc: 0.8964 - val_loss: 0.7549 - val_acc: 0.7636\n",
      "Epoch 6/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1624 - acc: 0.9378 - val_loss: 0.3493 - val_acc: 0.8871\n",
      "Epoch 7/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1428 - acc: 0.9438 - val_loss: 0.6258 - val_acc: 0.8264\n",
      "Epoch 8/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0652 - acc: 0.9747 - val_loss: 0.4623 - val_acc: 0.8857\n",
      "Epoch 9/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1117 - acc: 0.9566 - val_loss: 0.3717 - val_acc: 0.8929\n",
      "Epoch 10/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0509 - acc: 0.9807 - val_loss: 0.7607 - val_acc: 0.8129\n",
      "Epoch 11/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0749 - acc: 0.9737 - val_loss: 0.5928 - val_acc: 0.8771\n",
      "Epoch 12/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0543 - acc: 0.9814 - val_loss: 1.4349 - val_acc: 0.8036\n",
      "Epoch 13/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0333 - acc: 0.9875 - val_loss: 0.5426 - val_acc: 0.8950\n",
      "Epoch 14/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0295 - acc: 0.9884 - val_loss: 0.9479 - val_acc: 0.8743\n",
      "Epoch 15/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0410 - acc: 0.9840 - val_loss: 0.6996 - val_acc: 0.8679\n",
      "Epoch 16/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0140 - acc: 0.9960 - val_loss: 2.0491 - val_acc: 0.7900\n",
      "Epoch 17/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.1369 - acc: 0.9620 - val_loss: 0.5712 - val_acc: 0.8721\n",
      "Epoch 18/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0284 - acc: 0.9883 - val_loss: 0.4570 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0317 - acc: 0.9868 - val_loss: 0.5200 - val_acc: 0.8757\n",
      "Epoch 20/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.6596 - val_acc: 0.8986\n",
      "Epoch 21/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0133 - acc: 0.9950 - val_loss: 0.6527 - val_acc: 0.8914\n",
      "Epoch 22/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0285 - acc: 0.9891 - val_loss: 1.2111 - val_acc: 0.8086\n",
      "Epoch 23/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0843 - acc: 0.9727 - val_loss: 0.6097 - val_acc: 0.8857\n",
      "Epoch 24/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0616 - acc: 0.9768 - val_loss: 0.7682 - val_acc: 0.8757\n",
      "Epoch 25/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0245 - acc: 0.9912 - val_loss: 1.2329 - val_acc: 0.8350\n",
      "Epoch 26/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0861 - acc: 0.9712 - val_loss: 0.4632 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0068 - acc: 0.9974 - val_loss: 0.6380 - val_acc: 0.9071\n",
      "Epoch 28/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.6385 - val_acc: 0.8993\n",
      "Epoch 29/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.7328 - val_acc: 0.9036\n",
      "Epoch 30/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.8923 - val_acc: 0.8579\n",
      "Epoch 31/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.5522 - val_acc: 0.9036\n",
      "Epoch 32/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.8977 - val_acc: 0.8850\n",
      "Epoch 33/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0068 - acc: 0.9976 - val_loss: 0.8712 - val_acc: 0.8800\n",
      "Epoch 34/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 3.9425e-04 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.9071\n",
      "Epoch 35/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.6437 - val_acc: 0.8964\n",
      "Epoch 36/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.6674 - val_acc: 0.9029\n",
      "Epoch 37/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.7905 - val_acc: 0.9014\n",
      "Epoch 38/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.7932 - val_acc: 0.8779\n",
      "Epoch 39/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.6975 - val_acc: 0.8886\n",
      "Epoch 40/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.7405 - val_acc: 0.8943\n",
      "Epoch 41/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0068 - acc: 0.9976 - val_loss: 0.8667 - val_acc: 0.8579\n",
      "Epoch 42/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.6485 - val_acc: 0.9029\n",
      "Epoch 43/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 4.0186e-04 - acc: 1.0000 - val_loss: 0.7907 - val_acc: 0.9043\n",
      "Epoch 44/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.3580e-04 - acc: 1.0000 - val_loss: 0.8162 - val_acc: 0.9071\n",
      "Epoch 45/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 3.4456e-05 - acc: 1.0000 - val_loss: 0.8143 - val_acc: 0.9014\n",
      "Epoch 46/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 5.1405e-05 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.9029\n",
      "Epoch 47/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 1.8410e-05 - acc: 1.0000 - val_loss: 0.8654 - val_acc: 0.9021\n",
      "Epoch 48/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 9.1663e-06 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.9021\n",
      "Epoch 49/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.4013e-05 - acc: 1.0000 - val_loss: 0.8910 - val_acc: 0.9043\n",
      "Epoch 50/50\n",
      "3713/3713 [==============================] - 11s 3ms/step - loss: 2.7067e-06 - acc: 1.0000 - val_loss: 0.8987 - val_acc: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd84eb36780>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_inc_angle.fit([trn_conv_features, Xinc], trn_labels, batch_size=batch_size, epochs=50, verbose=1,shuffle=True,\n",
    "#           callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack], validation_split=0.25)\n",
    "\n",
    "\n",
    "model_inc_angle.fit([trn_conv_features, Xinc_train], trn_labels,\n",
    "                                          batch_size=32, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=([val_conv_features, Xinc_valid], val_labels),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "        \n",
    "tbCallBack = TensorBoard(log_dir='/home/ubuntu/data/tensorboardlogs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3530 samples, validate on 883 samples\n",
      "Epoch 1/50\n",
      "3530/3530 [==============================] - 11s 3ms/step - loss: 0.1402 - acc: 0.9780 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0572 - acc: 0.9861 - val_loss: 0.0367 - val_acc: 0.9909\n",
      "Epoch 3/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0342 - acc: 0.9911 - val_loss: 0.0041 - val_acc: 0.9989\n",
      "Epoch 4/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0249 - acc: 0.9938 - val_loss: 0.0128 - val_acc: 0.9977\n",
      "Epoch 5/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0152 - acc: 0.9966 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0114 - acc: 0.9980 - val_loss: 7.2979e-04 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 5.9467e-04 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0048 - acc: 0.9994 - val_loss: 6.6906e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 5.7836e-04 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0035 - acc: 0.9997 - val_loss: 4.6886e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0033 - acc: 0.9997 - val_loss: 5.4393e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0032 - acc: 0.9997 - val_loss: 5.7187e-04 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 6.1439e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 6.4582e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0028 - acc: 0.9997 - val_loss: 3.9134e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0028 - acc: 0.9997 - val_loss: 3.7760e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 4.0253e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 5.8122e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "3328/3530 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 0.9997    \n",
      "Epoch 00019: reducing learning rate to 0.00010000000474974513.\n",
      "3530/3530 [==============================] - 10s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 5.8811e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 4.8069e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 4.0077e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 3.6030e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 3.3768e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 3.1990e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 3.0572e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 3.0430e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.9822e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.9518e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.9526e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.8579e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "3328/3530 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 00031: reducing learning rate to 1.0000000474974514e-05.\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.8396e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.8105e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 2.7872e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 2.7690e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7512e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.7339e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7254e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.7232e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "3328/3530 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 00039: reducing learning rate to 1.0000000656873453e-06.\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7213e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 2.7180e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7145e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7112e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7102e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.7075e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7084e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7080e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "3328/3530 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9997    \n",
      "Epoch 00047: reducing learning rate to 1.0000001111620805e-07.\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7045e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.7054e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7026e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "3530/3530 [==============================] - 9s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7020e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd84f480c88>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inc_angle.fit([all_conv_features, Xinc], all_labels,\n",
    "                                          batch_size=batch_size, \n",
    "                                          epochs=50,\n",
    "                                          validation_split=0.25,\n",
    "                                          verbose=1,\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4413/4413 [==============================] - 7s 2ms/step\n",
      "Train score: 0.00213907369083\n",
      "Train accuracy: 0.999773396782\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "score = model_inc_angle.evaluate([all_conv_features, Xinc], all_labels, verbose=1)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ubuntu/data/iceberg'\n",
    "\n",
    "df_test = pd.read_json(os.path.join(data_dir, 'test.json'))\n",
    "df_test.inc_angle = df_test.inc_angle.replace('na',0)\n",
    "Xtest = (get_scaled_imgs(df_test))\n",
    "Xtest_inc = df_test.inc_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8424, 224, 224, 3), (8424,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape, Xtest_inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv_features = vgg_base.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model_inc_angle.predict([test_conv_features, Xtest_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99957806"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id    is_iceberg\n",
      "0  5941774d  3.952795e-01\n",
      "1  4023181e  9.995781e-01\n",
      "2  b20200e4  9.970840e-01\n",
      "3  e7f018bb  9.993762e-01\n",
      "4  4371c8c3  9.994198e-01\n",
      "5  a8d9b1fd  9.996321e-01\n",
      "6  29e7727e  1.797852e-32\n",
      "7  92a51ffb  9.995446e-01\n",
      "8  c769ac97  1.552835e-15\n",
      "9  aee0547d  1.769691e-29\n"
     ]
    }
   ],
   "source": [
    "# this is the right way round\n",
    "submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test[:,1].reshape((pred_test[:,1].shape[0]))})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('cnn_train_' + str(np.around(score[1], decimals=2))  + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/git/learningWithKaggle/ice'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
