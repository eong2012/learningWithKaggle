{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/ubuntu/data/iceberg'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.layers.merge import Add, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "import keras\n",
    "import os\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras import __version__\n",
    "print(__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "\n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "#         imgs.append(np.dstack((band_1, band_2, band_3)))\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "\n",
    "    return np.array(imgs)\n",
    "\n",
    "def get_more_images(imgs):\n",
    "    \n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "      \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        a=imgs[i,:,:,0]\n",
    "        b=imgs[i,:,:,1]\n",
    "        c=imgs[i,:,:,2]\n",
    "        \n",
    "        av=cv2.flip(a,1)\n",
    "        ah=cv2.flip(a,0)\n",
    "        bv=cv2.flip(b,1)\n",
    "        bh=cv2.flip(b,0)\n",
    "        cv=cv2.flip(c,1)\n",
    "        ch=cv2.flip(c,0)\n",
    "        \n",
    "        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n",
    "        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n",
    "      \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "       \n",
    "    more_images = np.concatenate((imgs,v,h))\n",
    "    \n",
    "    return more_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_json(os.path.join(data_dir, 'train.json'))\n",
    "Xtrain = get_scaled_imgs(df_train)\n",
    "Ytrain = np.array(df_train['is_iceberg'])\n",
    "\n",
    "df_train.inc_angle = df_train.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(df_train.inc_angle>0)\n",
    "\n",
    "Ytrain = Ytrain[idx_tr[0]]\n",
    "Xtrain = Xtrain[idx_tr[0],...]\n",
    "Xinc = df_train.inc_angle[idx_tr[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72976856454753891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[1,:,:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1323, 75, 75, 3), (148, 75, 75, 3), (1323,), (148,), (1323,), (148,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a train and validation split, 75% of data used in training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, X_inc_train, X_inc_valid, Y_train, Y_valid = train_test_split(Xtrain,\n",
    "                                    Xinc, Ytrain, random_state=666, train_size=0.9, test_size=0.1)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_angle_train.shape, X_angle_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3969, 75, 75, 3), (3969,), (3969,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = get_more_images(X_train)\n",
    "X_inc_train = np.concatenate((X_inc_train,X_inc_train,X_inc_train))\n",
    "Y_train = np.concatenate((Y_train,Y_train,Y_train))\n",
    "\n",
    "X_train.shape, X_inc_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "        \n",
    "tbCallBack = TensorBoard(log_dir='/home/ubuntu/data/tensorboardlogs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "input_shape = (75, 75, 3)\n",
    "num_classes = 2\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "inc_angle_input = Input(shape=(1,))\n",
    "\n",
    "# CNN 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "# CNN 4\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "m = Concatenate()([inc_angle_input, x])\n",
    "m = Dense(512, activation='relu')(m)\n",
    "m = Dense(256, activation='relu')(m)\n",
    "out = Dense(2, activation='sigmoid')(m)\n",
    "# out = Activation('softmax')(m)\n",
    "\n",
    "# optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "optimizer = Adam(lr=0.0015, decay=0.0)\n",
    "model = Model(inputs=[classifier_input, inc_angle_input], outputs=out)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3969 samples, validate on 148 samples\n",
      "Epoch 1/50\n",
      "3969/3969 [==============================] - 9s 2ms/step - loss: 0.7605 - acc: 0.4961 - val_loss: 0.7908 - val_acc: 0.5135\n",
      "Epoch 2/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.7111 - acc: 0.5574 - val_loss: 0.8261 - val_acc: 0.4831\n",
      "Epoch 3/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.5430 - acc: 0.7171 - val_loss: 0.5245 - val_acc: 0.7770\n",
      "Epoch 4/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4822 - acc: 0.7754 - val_loss: 0.6037 - val_acc: 0.7635\n",
      "Epoch 5/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4892 - acc: 0.7821 - val_loss: 0.4916 - val_acc: 0.7770\n",
      "Epoch 6/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4403 - acc: 0.8016 - val_loss: 0.4742 - val_acc: 0.7872\n",
      "Epoch 7/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4196 - acc: 0.8185 - val_loss: 0.4496 - val_acc: 0.8007\n",
      "Epoch 8/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4244 - acc: 0.8137 - val_loss: 0.4485 - val_acc: 0.8041\n",
      "Epoch 9/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.4208 - acc: 0.8188 - val_loss: 0.4200 - val_acc: 0.8378 loss: 0.4220 - acc: 0\n",
      "Epoch 10/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.3730 - acc: 0.8278 - val_loss: 0.2732 - val_acc: 0.9088\n",
      "Epoch 11/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.3001 - acc: 0.8619 - val_loss: 0.3652 - val_acc: 0.8142\n",
      "Epoch 12/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2640 - acc: 0.8849 - val_loss: 0.2300 - val_acc: 0.8919\n",
      "Epoch 13/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2643 - acc: 0.8820 - val_loss: 0.3137 - val_acc: 0.8547\n",
      "Epoch 14/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2481 - acc: 0.8958 - val_loss: 0.1710 - val_acc: 0.9392\n",
      "Epoch 15/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2190 - acc: 0.9040 - val_loss: 0.2140 - val_acc: 0.9291\n",
      "Epoch 16/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2022 - acc: 0.9180 - val_loss: 0.2877 - val_acc: 0.8412\n",
      "Epoch 17/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2243 - acc: 0.9055 - val_loss: 0.1866 - val_acc: 0.9392\n",
      "Epoch 18/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1951 - acc: 0.9200 - val_loss: 0.4088 - val_acc: 0.8041\n",
      "Epoch 19/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.3765 - acc: 0.8456 - val_loss: 0.2870 - val_acc: 0.9088\n",
      "Epoch 20/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.3405 - acc: 0.8474 - val_loss: 0.2130 - val_acc: 0.9189\n",
      "Epoch 21/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2261 - acc: 0.9092 - val_loss: 0.2048 - val_acc: 0.9291\n",
      "Epoch 22/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1990 - acc: 0.9182 - val_loss: 0.2530 - val_acc: 0.8986\n",
      "Epoch 23/50\n",
      "3968/3969 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9070- ETA: 4s - lo\n",
      "Epoch 00023: reducing learning rate to 0.00015000000130385163.\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.2322 - acc: 0.9070 - val_loss: 0.1861 - val_acc: 0.9257\n",
      "Epoch 24/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1865 - acc: 0.9264 - val_loss: 0.1599 - val_acc: 0.9459\n",
      "Epoch 25/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1830 - acc: 0.9261 - val_loss: 0.1544 - val_acc: 0.9459\n",
      "Epoch 26/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1752 - acc: 0.9306 - val_loss: 0.1588 - val_acc: 0.9459\n",
      "Epoch 27/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1653 - acc: 0.9345 - val_loss: 0.1613 - val_acc: 0.9459\n",
      "Epoch 28/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1692 - acc: 0.9327 - val_loss: 0.1572 - val_acc: 0.9459\n",
      "Epoch 29/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1631 - acc: 0.9283 - val_loss: 0.1574 - val_acc: 0.9527\n",
      "Epoch 30/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1661 - acc: 0.9345 - val_loss: 0.1493 - val_acc: 0.9595\n",
      "Epoch 31/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1595 - acc: 0.9350 - val_loss: 0.1552 - val_acc: 0.9459 loss: 0.1597 - acc: 0.93\n",
      "Epoch 32/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1676 - acc: 0.9308 - val_loss: 0.1490 - val_acc: 0.9493\n",
      "Epoch 33/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1748 - acc: 0.9295 - val_loss: 0.1576 - val_acc: 0.9527\n",
      "Epoch 34/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1594 - acc: 0.9332 - val_loss: 0.1474 - val_acc: 0.9527A: 0s - loss: 0.1560 - acc: 0\n",
      "Epoch 35/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1565 - acc: 0.9369 - val_loss: 0.1507 - val_acc: 0.9459\n",
      "Epoch 36/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1596 - acc: 0.9339 - val_loss: 0.1442 - val_acc: 0.9662\n",
      "Epoch 37/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1761 - acc: 0.9257 - val_loss: 0.1589 - val_acc: 0.9459\n",
      "Epoch 38/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1576 - acc: 0.9347 - val_loss: 0.1573 - val_acc: 0.9459\n",
      "Epoch 39/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1506 - acc: 0.9383 - val_loss: 0.1606 - val_acc: 0.9459\n",
      "Epoch 40/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1605 - acc: 0.9347 - val_loss: 0.1579 - val_acc: 0.9527\n",
      "Epoch 41/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1526 - acc: 0.9376 - val_loss: 0.1548 - val_acc: 0.9662\n",
      "Epoch 42/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1684 - acc: 0.9286 - val_loss: 0.1654 - val_acc: 0.9459\n",
      "Epoch 43/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1575 - acc: 0.9340 - val_loss: 0.1729 - val_acc: 0.9527- loss: 0.1603 - acc: \n",
      "Epoch 44/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1476 - acc: 0.9384 - val_loss: 0.1501 - val_acc: 0.9595\n",
      "Epoch 45/50\n",
      "3968/3969 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9313\n",
      "Epoch 00045: reducing learning rate to 1.500000071246177e-05.\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1640 - acc: 0.9313 - val_loss: 0.1535 - val_acc: 0.9459\n",
      "Epoch 46/50\n",
      "3969/3969 [==============================] - 6s 2ms/step - loss: 0.1508 - acc: 0.9414 - val_loss: 0.1529 - val_acc: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd91c2fa748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit([X_train, X_inc_train], to_categorical(Y_train),\n",
    "                                          batch_size=128, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=([X_valid, X_inc_valid], to_categorical(Y_valid)),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/ubuntu/data/iceberg/results/weights/norm_image_inc_angle-Copy1_94_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471/1471 [==============================] - 1s 638us/step\n",
      "Train score: 0.126904439938\n",
      "Train accuracy: 0.956152277362\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "score = model.evaluate([Xtrain,Xinc], to_categorical(Ytrain), verbose=1)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "df_test = pd.read_json(os.path.join(data_dir, 'test.json'))\n",
    "df_test.inc_angle = df_test.inc_angle.replace('na',0)\n",
    "Xtest = (get_scaled_imgs(df_test))\n",
    "Xtest_inc = df_test.inc_angle\n",
    "pred_test = model.predict([Xtest,Xtest_inc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id    is_iceberg\n",
      "0  5941774d  1.164687e-01\n",
      "1  4023181e  9.736597e-01\n",
      "2  b20200e4  5.172412e-05\n",
      "3  e7f018bb  9.997181e-01\n",
      "4  4371c8c3  9.265997e-01\n",
      "5  a8d9b1fd  9.874319e-01\n",
      "6  29e7727e  2.264617e-01\n",
      "7  92a51ffb  9.965637e-01\n",
      "8  c769ac97  1.253932e-05\n",
      "9  aee0547d  5.985670e-07\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test[:,1].reshape((pred_test[:,1].shape[0]))})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('/home/ubuntu/data/iceberg/results/final_preds/cnn_model1_aug_' + str(np.around(score[1], decimals=2))  + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pseudo labelling using the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the correct way round with [:,1]\n",
    "idx_pred_1 = (np.where(pred_test[:,1]>0.95))\n",
    "idx_pred_0 = (np.where(pred_test[:,1]<0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8424, 1), (3969, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_inc.shape, X_inc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest_inc = np.expand_dims(Xtest_inc, axis=1)\n",
    "X_inc_train = np.expand_dims(X_inc_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9763, 75, 75, 3), (9763,), (9763, 1, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_pl = np.concatenate((X_train, Xtest[idx_pred_1[0],...], Xtest[idx_pred_0[0],...]))\n",
    "Ytrain_pl = np.concatenate((Y_train, np.ones(idx_pred_1[0].shape[0]), np.zeros(idx_pred_0[0].shape[0])))\n",
    "Xinc_pl = np.concatenate((X_inc_train, Xtest_inc[idx_pred_1[0],...], Xtest_inc[idx_pred_0[0],...]))\n",
    "\n",
    "Xtrain_pl.shape, Ytrain_pl.shape, Xinc_pl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinc_pl = np.squeeze(Xinc_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "input_shape = (75, 75, 3)\n",
    "num_classes = 2\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "inc_angle_input = Input(shape=(1,))\n",
    "\n",
    "# CNN 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "# CNN 4\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "m = Concatenate()([inc_angle_input, x])\n",
    "m = Dense(512, activation='relu')(m)\n",
    "m = Dense(256, activation='relu')(m)\n",
    "out = Dense(2, activation='sigmoid')(m)\n",
    "# out = Activation('softmax')(m)\n",
    "\n",
    "# optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "optimizer = Adam(lr=0.0015, decay=0.0)\n",
    "model2 = Model(inputs=[classifier_input, inc_angle_input], outputs=out)\n",
    "model2.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9763 samples, validate on 148 samples\n",
      "Epoch 1/50\n",
      "9763/9763 [==============================] - 16s 2ms/step - loss: 0.6166 - acc: 0.6713 - val_loss: 0.6229 - val_acc: 0.7128\n",
      "Epoch 2/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.3354 - acc: 0.8669 - val_loss: 0.5192 - val_acc: 0.7770\n",
      "Epoch 3/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.2501 - acc: 0.9042 - val_loss: 0.4833 - val_acc: 0.7939 loss: 0.2537 - acc\n",
      "Epoch 4/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.2342 - acc: 0.9029 - val_loss: 0.2614 - val_acc: 0.8716\n",
      "Epoch 5/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1608 - acc: 0.9301 - val_loss: 0.2916 - val_acc: 0.8649\n",
      "Epoch 6/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1422 - acc: 0.9369 - val_loss: 0.2314 - val_acc: 0.8986\n",
      "Epoch 7/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1399 - acc: 0.9404 - val_loss: 0.2208 - val_acc: 0.9054\n",
      "Epoch 8/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1325 - acc: 0.9407 - val_loss: 0.1957 - val_acc: 0.9189\n",
      "Epoch 9/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1289 - acc: 0.9458 - val_loss: 0.1671 - val_acc: 0.9324 - loss: 0.1287 - acc: 0.946\n",
      "Epoch 10/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1017 - acc: 0.9579 - val_loss: 0.1600 - val_acc: 0.9392\n",
      "Epoch 11/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.1026 - acc: 0.9592 - val_loss: 0.2405 - val_acc: 0.8919\n",
      "Epoch 12/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0954 - acc: 0.9640 - val_loss: 0.1910 - val_acc: 0.9426\n",
      "Epoch 13/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0901 - acc: 0.9655 - val_loss: 0.2145 - val_acc: 0.8986\n",
      "Epoch 14/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0888 - acc: 0.9667 - val_loss: 0.1794 - val_acc: 0.9088\n",
      "Epoch 15/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0872 - acc: 0.9643 - val_loss: 0.1703 - val_acc: 0.9189\n",
      "Epoch 16/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0786 - acc: 0.9681 - val_loss: 0.1504 - val_acc: 0.9392\n",
      "Epoch 17/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0843 - acc: 0.9686 - val_loss: 0.1670 - val_acc: 0.9257\n",
      "Epoch 18/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0755 - acc: 0.9703 - val_loss: 0.1800 - val_acc: 0.9392\n",
      "Epoch 19/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0765 - acc: 0.9700 - val_loss: 0.1476 - val_acc: 0.9493\n",
      "Epoch 20/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0699 - acc: 0.9719 - val_loss: 0.2285 - val_acc: 0.9088: 8s - loss: 0.0692 - acc: 0. \n",
      "Epoch 21/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0869 - acc: 0.9654 - val_loss: 0.1955 - val_acc: 0.9088\n",
      "Epoch 22/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0681 - acc: 0.9743 - val_loss: 0.2343 - val_acc: 0.8581\n",
      "Epoch 23/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0739 - acc: 0.9713 - val_loss: 0.1877 - val_acc: 0.8986\n",
      "Epoch 24/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0705 - acc: 0.9728 - val_loss: 0.1635 - val_acc: 0.9459\n",
      "Epoch 25/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0596 - acc: 0.9769 - val_loss: 0.1316 - val_acc: 0.9324\n",
      "Epoch 26/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0594 - acc: 0.9773 - val_loss: 0.1956 - val_acc: 0.8986\n",
      "Epoch 27/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0675 - acc: 0.9725 - val_loss: 0.1985 - val_acc: 0.9561\n",
      "Epoch 28/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0559 - acc: 0.9783 - val_loss: 0.2392 - val_acc: 0.9324\n",
      "Epoch 29/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0567 - acc: 0.9779 - val_loss: 0.1464 - val_acc: 0.9291\n",
      "Epoch 30/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0507 - acc: 0.9802 - val_loss: 0.1435 - val_acc: 0.9527\n",
      "Epoch 31/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0486 - acc: 0.9820 - val_loss: 0.2042 - val_acc: 0.9155\n",
      "Epoch 32/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0590 - acc: 0.9784 - val_loss: 0.1604 - val_acc: 0.9324\n",
      "Epoch 33/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0431 - acc: 0.9840 - val_loss: 0.1138 - val_acc: 0.9561\n",
      "Epoch 34/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0491 - acc: 0.9820 - val_loss: 0.1949 - val_acc: 0.9392\n",
      "Epoch 35/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0347 - acc: 0.9855 - val_loss: 0.1416 - val_acc: 0.9730\n",
      "Epoch 36/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0342 - acc: 0.9870 - val_loss: 0.2446 - val_acc: 0.8919\n",
      "Epoch 37/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0346 - acc: 0.9875 - val_loss: 0.1593 - val_acc: 0.9324\n",
      "Epoch 38/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0394 - acc: 0.9853 - val_loss: 0.1631 - val_acc: 0.9459\n",
      "Epoch 39/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0364 - acc: 0.9862 - val_loss: 0.1719 - val_acc: 0.9257\n",
      "Epoch 40/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0423 - acc: 0.9848 - val_loss: 0.1674 - val_acc: 0.9257\n",
      "Epoch 41/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0429 - acc: 0.9852 - val_loss: 0.1439 - val_acc: 0.9324\n",
      "Epoch 42/50\n",
      "9728/9763 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9903\n",
      "Epoch 00042: reducing learning rate to 0.00015000000130385163.\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.2196 - val_acc: 0.9459\n",
      "Epoch 43/50\n",
      "9763/9763 [==============================] - 15s 2ms/step - loss: 0.0238 - acc: 0.9921 - val_loss: 0.1928 - val_acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd83abb9780>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([Xtrain_pl, Xinc_pl], to_categorical(Ytrain_pl),\n",
    "                                          batch_size=128, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=([X_valid, X_inc_valid], to_categorical(Y_valid)),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as well as adding the pseudo labelling, augment the pseudo labelled data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29289, 75, 75, 3), (29289,), (29289,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this way will reaugment the orginal images, perhaps doesn't matter? \n",
    "\n",
    "Xtrain_pl = get_more_images(Xtrain_pl)\n",
    "Xinc_pl = np.concatenate((Xinc_pl,Xinc_pl,Xinc_pl))\n",
    "Ytrain_pl = np.concatenate((Ytrain_pl,Ytrain_pl,Ytrain_pl))\n",
    "\n",
    "Xtrain_pl.shape, Ytrain_pl.shape, Xinc_pl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29289 samples, validate on 148 samples\n",
      "Epoch 1/50\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0408 - acc: 0.9864 - val_loss: 0.1343 - val_acc: 0.9561\n",
      "Epoch 2/50\n",
      "29289/29289 [==============================] - 45s 2ms/step - loss: 0.0367 - acc: 0.9876 - val_loss: 0.1561 - val_acc: 0.9459\n",
      "Epoch 3/50\n",
      "29289/29289 [==============================] - 45s 2ms/step - loss: 0.0316 - acc: 0.9882 - val_loss: 0.1464 - val_acc: 0.9662\n",
      "Epoch 4/50\n",
      "29289/29289 [==============================] - 45s 2ms/step - loss: 0.0343 - acc: 0.9881 - val_loss: 0.1358 - val_acc: 0.9595 acc: 0.98 - ETA: 5s - loss: 0.0344 - acc: 0.988 - ETA: 4s - loss: 0.0344 - acc: 0.987 - ETA: 4s - lo\n",
      "Epoch 5/50\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0291 - acc: 0.9892 - val_loss: 0.1477 - val_acc: 0.9595\n",
      "Epoch 6/50\n",
      "29289/29289 [==============================] - 45s 2ms/step - loss: 0.0299 - acc: 0.9893 - val_loss: 0.1663 - val_acc: 0.9527\n",
      "Epoch 7/50\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0278 - acc: 0.9900 - val_loss: 0.1594 - val_acc: 0.9595: 6s - loss: 0.0276 - acc: 0.99 - ETA: 5s - lo - ETA: 1s - loss: 0.0277 - acc: \n",
      "Epoch 8/50\n",
      "29289/29289 [==============================] - 45s 2ms/step - loss: 0.0257 - acc: 0.9907 - val_loss: 0.1730 - val_acc: 0.9459\n",
      "Epoch 9/50\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0242 - acc: 0.9910 - val_loss: 0.1678 - val_acc: 0.9662\n",
      "Epoch 10/50\n",
      "29184/29289 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9916\n",
      "Epoch 00010: reducing learning rate to 1.500000071246177e-05.\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0232 - acc: 0.9917 - val_loss: 0.1704 - val_acc: 0.9595\n",
      "Epoch 11/50\n",
      "29289/29289 [==============================] - 46s 2ms/step - loss: 0.0210 - acc: 0.9923 - val_loss: 0.1718 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd83aa742b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([Xtrain_pl, Xinc_pl], to_categorical(Ytrain_pl),\n",
    "                                          batch_size=128, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=([X_valid, X_inc_valid], to_categorical(Y_valid)),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save_weights('/home/ubuntu/data/iceberg/results/weights/norm_image_inc_angle-Copy1_model2_96_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471/1471 [==============================] - 1s 645us/step\n",
      "Train score: 0.0224028783765\n",
      "Train accuracy: 0.99388171312\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "score = model2.evaluate([Xtrain,Xinc], to_categorical(Ytrain), verbose=1)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "df_test = pd.read_json(os.path.join(data_dir, 'test.json'))\n",
    "df_test.inc_angle = df_test.inc_angle.replace('na',0)\n",
    "Xtest = (get_scaled_imgs(df_test))\n",
    "Xtest_inc = df_test.inc_angle\n",
    "pred_test = model.predict([Xtest,Xtest_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id    is_iceberg\n",
      "0  5941774d  1.164687e-01\n",
      "1  4023181e  9.736597e-01\n",
      "2  b20200e4  5.172412e-05\n",
      "3  e7f018bb  9.997181e-01\n",
      "4  4371c8c3  9.265997e-01\n",
      "5  a8d9b1fd  9.874319e-01\n",
      "6  29e7727e  2.264617e-01\n",
      "7  92a51ffb  9.965637e-01\n",
      "8  c769ac97  1.253932e-05\n",
      "9  aee0547d  5.985670e-07\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test[:,1].reshape((pred_test[:,1].shape[0]))})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('/home/ubuntu/data/iceberg/results/final_preds/cnn_model2_pseudo_' + str(np.around(score[1], decimals=2))  + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8424, 75, 75, 3), (8424,), (8424, 2))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape, Xtest_inc.shape, pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25272, 75, 75, 3), (25272,), (25272, 2))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = get_more_images(Xtest)\n",
    "Xtest_inc = np.concatenate((Xtest_inc,Xtest_inc,Xtest_inc))\n",
    "pred_test = np.concatenate((pred_test, pred_test, pred_test))\n",
    "\n",
    "Xtest.shape, Xtest_inc.shape, pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the correct way round with [:,1]\n",
    "idx_pred_1 = (np.where(pred_test[:,1]>0.95))\n",
    "idx_pred_0 = (np.where(pred_test[:,1]<0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xtest_inc = np.expand_dims(Xtest_inc, axis=1)\n",
    "X_inc_train = np.expand_dims(X_inc_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_inc_train = np.squeeze(X_inc_train)\n",
    "X_inc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21351, 75, 75, 3), (21351,), (21351, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_pl = np.concatenate((X_train, Xtest[idx_pred_1[0],...], Xtest[idx_pred_0[0],...]))\n",
    "Ytrain_pl = np.concatenate((Y_train, np.ones(idx_pred_1[0].shape[0]), np.zeros(idx_pred_0[0].shape[0])))\n",
    "Xinc_pl = np.concatenate((X_inc_train, Xtest_inc[idx_pred_1[0],...], Xtest_inc[idx_pred_0[0],...]))\n",
    "\n",
    "Xtrain_pl.shape, Ytrain_pl.shape, Xinc_pl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.4\n",
    "input_shape = (75, 75, 3)\n",
    "num_classes = 2\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "inc_angle_input = Input(shape=(1,))\n",
    "\n",
    "# CNN 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# CNN 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "# CNN 4\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "# x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(p/2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "m = Concatenate()([inc_angle_input, x])\n",
    "m = Dense(512, activation='relu')(m)\n",
    "m = Dense(256, activation='relu')(m)\n",
    "out = Dense(2, activation='sigmoid')(m)\n",
    "# out = Activation('softmax')(m)\n",
    "\n",
    "# optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "optimizer = Adam(lr=0.0015, decay=0.0)\n",
    "model3 = Model(inputs=[classifier_input, inc_angle_input], outputs=out)\n",
    "model3.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21351 samples, validate on 148 samples\n",
      "Epoch 1/50\n",
      "21351/21351 [==============================] - 32s 2ms/step - loss: 0.5016 - acc: 0.7432 - val_loss: 0.6544 - val_acc: 0.7973\n",
      "Epoch 2/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.1927 - acc: 0.9379 - val_loss: 0.4042 - val_acc: 0.8716\n",
      "Epoch 3/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.1396 - acc: 0.9557 - val_loss: 0.3343 - val_acc: 0.8784\n",
      "Epoch 4/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0918 - acc: 0.9642 - val_loss: 0.1993 - val_acc: 0.9189\n",
      "Epoch 5/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0761 - acc: 0.9714 - val_loss: 0.2107 - val_acc: 0.9122\n",
      "Epoch 6/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0686 - acc: 0.9722 - val_loss: 0.1700 - val_acc: 0.9122\n",
      "Epoch 7/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0643 - acc: 0.9747 - val_loss: 0.2037 - val_acc: 0.9189\n",
      "Epoch 8/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0582 - acc: 0.9772 - val_loss: 0.1633 - val_acc: 0.9257\n",
      "Epoch 9/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0554 - acc: 0.9790 - val_loss: 0.1598 - val_acc: 0.9392\n",
      "Epoch 10/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0515 - acc: 0.9798 - val_loss: 0.1718 - val_acc: 0.9324\n",
      "Epoch 11/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0616 - acc: 0.9761 - val_loss: 0.1860 - val_acc: 0.9392\n",
      "Epoch 12/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0530 - acc: 0.9790 - val_loss: 0.1924 - val_acc: 0.9358\n",
      "Epoch 13/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0569 - acc: 0.9789 - val_loss: 0.1941 - val_acc: 0.9291\n",
      "Epoch 14/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0526 - acc: 0.9797 - val_loss: 0.1685 - val_acc: 0.9459\n",
      "Epoch 15/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0461 - acc: 0.9820 - val_loss: 0.1493 - val_acc: 0.9426\n",
      "Epoch 16/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0456 - acc: 0.9830 - val_loss: 0.1901 - val_acc: 0.9324\n",
      "Epoch 17/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0484 - acc: 0.9819 - val_loss: 0.1766 - val_acc: 0.9358\n",
      "Epoch 18/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0446 - acc: 0.9832 - val_loss: 0.1758 - val_acc: 0.9392\n",
      "Epoch 19/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0434 - acc: 0.9831 - val_loss: 0.1957 - val_acc: 0.9324\n",
      "Epoch 20/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0503 - acc: 0.9814 - val_loss: 0.1936 - val_acc: 0.9358\n",
      "Epoch 21/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0415 - acc: 0.9834 - val_loss: 0.2176 - val_acc: 0.9155\n",
      "Epoch 22/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0427 - acc: 0.9836 - val_loss: 0.1797 - val_acc: 0.9324\n",
      "Epoch 23/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0447 - acc: 0.9830 - val_loss: 0.1722 - val_acc: 0.9459\n",
      "Epoch 24/50\n",
      "21248/21351 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9854\n",
      "Epoch 00024: reducing learning rate to 0.00015000000130385163.\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0402 - acc: 0.9855 - val_loss: 0.1659 - val_acc: 0.9493\n",
      "Epoch 25/50\n",
      "21351/21351 [==============================] - 32s 1ms/step - loss: 0.0309 - acc: 0.9881 - val_loss: 0.1602 - val_acc: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8a70bb940>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit([Xtrain_pl, Xinc_pl], to_categorical(Ytrain_pl),\n",
    "                                          batch_size=256, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=([X_valid, X_inc_valid], to_categorical(Y_valid)),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.save_weights('/home/ubuntu/data/iceberg/results/weights/norm_image_inc_angle-Copy1_model3_95_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471/1471 [==============================] - 1s 646us/step\n",
      "Train score: 0.110659150335\n",
      "Train accuracy: 0.956492182189\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "score = model3.evaluate([Xtrain,Xinc], to_categorical(Ytrain), verbose=1)\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "df_test = pd.read_json(os.path.join(data_dir, 'test.json'))\n",
    "df_test.inc_angle = df_test.inc_angle.replace('na',0)\n",
    "Xtest = (get_scaled_imgs(df_test))\n",
    "Xtest_inc = df_test.inc_angle\n",
    "pred_test = model.predict([Xtest,Xtest_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89999998"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit_nums = np.clip(pred_test[:,1], 0.1, 0.9)\n",
    "submit_nums[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id    is_iceberg\n",
      "0  5941774d  1.164687e-01\n",
      "1  4023181e  9.736597e-01\n",
      "2  b20200e4  5.172412e-05\n",
      "3  e7f018bb  9.997181e-01\n",
      "4  4371c8c3  9.265997e-01\n",
      "5  a8d9b1fd  9.874319e-01\n",
      "6  29e7727e  2.264617e-01\n",
      "7  92a51ffb  9.965637e-01\n",
      "8  c769ac97  1.253932e-05\n",
      "9  aee0547d  5.985670e-07\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test[:,1].reshape((pred_test[:,1].shape[0]))})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('/home/ubuntu/data/iceberg/results/final_preds/cnn_model3_pseudo_aug_' + str(np.around(score[1], decimals=2))  + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 4)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4413/4413 [==============================] - 3s 600us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13649047835023664, 0.95014729196998826]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([Xtrain,Xinc], to_categorical(Ytrain), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
