{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '/home/ubuntu/data/iceberg'\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create generators from the pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        #rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True, \n",
    "        preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(#rescale=1./255, \n",
    "                                  preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/iceberg/pngs/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=30,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/iceberg/pngs/valid',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=20,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precompute the convolutional layers and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_precomputed_data(model, generator):\n",
    "    filenames = generator.filenames\n",
    "    conv_features = model.predict_generator(generator, (generator.n/generator.batch_size))\n",
    "    labels_onehot = to_categorical(generator.classes)\n",
    "    labels = generator.classes\n",
    "    return (filenames, conv_features, labels_onehot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_filenames, trn_conv_features, trn_labels, trn_labels_1 = create_precomputed_data(vgg_base, train_generator)\n",
    "val_filenames, val_conv_features, val_labels, val_labels_1 = create_precomputed_data(vgg_base, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 7, 7, 512)\n",
      "(400, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print(trn_conv_features.shape)\n",
    "print(val_conv_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(trn_filenames) == 1200, \"trn_filenames not as expected\"\n",
    "assert trn_conv_features.shape == (1200, 7, 7, 512), \"trn_conv_features not as expected\"\n",
    "assert trn_labels.shape == (1200, 2), \"trn_labels not as expected\"\n",
    "\n",
    "assert len(val_filenames) == 400, \"val_filenames not as expected\"\n",
    "assert val_conv_features.shape == (400, 7, 7, 512), \"val_conv_features not as expected\"\n",
    "assert val_labels.shape == (400, 2), \"val_labels not as expected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/ubuntu/data/iceberg/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_precomputed_data(filenames, conv_feats, labels, features_base_name=\"VGG16_conv_feats/trn_\"):\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat', np.array(filenames))\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat', conv_feats)\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat', np.array(labels))\n",
    "    \n",
    "save_precomputed_data(trn_filenames, trn_conv_features, trn_labels, \"VGG16_conv_feats/trn_\")\n",
    "save_precomputed_data(val_filenames, val_conv_features, val_labels, \"VGG16_conv_feats/val_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_precomputed_data(features_base_name=\"VGG16_conv_feats/trn_\"):\n",
    "    filenames = load_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat').tolist()\n",
    "    conv_feats = load_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat')\n",
    "    labels = load_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat')\n",
    "    return filenames, conv_feats, labels\n",
    "\n",
    "trn_filenames, trn_conv_features, trn_labels = load_precomputed_data(\"VGG16_conv_feats/trn_\")\n",
    "val_filenames, val_conv_features, val_labels = load_precomputed_data(\"VGG16_conv_feats/val_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create simple model on top of the conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create classifier model\n",
    "p = 0.3 \n",
    "\n",
    "classifier_input_shape = (7, 7, 512)\n",
    "classifier_input = Input(shape=classifier_input_shape)\n",
    "\n",
    "x= Flatten()(classifier_input)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(256, activation='sigmoid')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "                                                     \n",
    "classifier_model_v1 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v1.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir='/home/ubuntu/data/iceberg/tb_logs_ice/', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.7329 - acc: 0.5892 - val_loss: 0.6477 - val_acc: 0.5950\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.6659 - acc: 0.6375 - val_loss: 0.6020 - val_acc: 0.6375\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.6418 - acc: 0.6408 - val_loss: 0.5882 - val_acc: 0.6200\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.6154 - acc: 0.6525 - val_loss: 0.5812 - val_acc: 0.6450\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.5688 - acc: 0.6933 - val_loss: 0.5296 - val_acc: 0.7275\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.5518 - acc: 0.7100 - val_loss: 0.5517 - val_acc: 0.7175\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 1s 733us/step - loss: 0.5086 - acc: 0.7467 - val_loss: 0.4749 - val_acc: 0.7650\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 1s 744us/step - loss: 0.5215 - acc: 0.7250 - val_loss: 0.4889 - val_acc: 0.7600\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.4897 - acc: 0.7475 - val_loss: 0.6423 - val_acc: 0.6800\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.4597 - acc: 0.7942 - val_loss: 0.4815 - val_acc: 0.7475\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.4296 - acc: 0.7942 - val_loss: 0.4826 - val_acc: 0.7750\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 1s 732us/step - loss: 0.4372 - acc: 0.7933 - val_loss: 0.4646 - val_acc: 0.7600\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.3804 - acc: 0.8333 - val_loss: 0.4888 - val_acc: 0.7650\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.3904 - acc: 0.8175 - val_loss: 0.4717 - val_acc: 0.7550\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.3360 - acc: 0.8475 - val_loss: 0.4508 - val_acc: 0.7650\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 1s 739us/step - loss: 0.3275 - acc: 0.8500 - val_loss: 0.4867 - val_acc: 0.7575\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.2693 - acc: 0.8867 - val_loss: 0.4867 - val_acc: 0.7800\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.2389 - acc: 0.9000 - val_loss: 0.5385 - val_acc: 0.7800\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.2137 - acc: 0.9017 - val_loss: 0.6093 - val_acc: 0.7525\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.1999 - acc: 0.9233 - val_loss: 0.6775 - val_acc: 0.7325\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.1813 - acc: 0.9208 - val_loss: 0.5522 - val_acc: 0.7900\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.1597 - acc: 0.9333 - val_loss: 0.6817 - val_acc: 0.8000\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.1202 - acc: 0.9475 - val_loss: 0.6066 - val_acc: 0.7900\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 1s 733us/step - loss: 0.1335 - acc: 0.9558 - val_loss: 0.5624 - val_acc: 0.8050\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 1s 741us/step - loss: 0.1216 - acc: 0.9500 - val_loss: 0.6182 - val_acc: 0.8125\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.0909 - acc: 0.9742 - val_loss: 0.7565 - val_acc: 0.7825\n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.0976 - acc: 0.9583 - val_loss: 0.6907 - val_acc: 0.8125\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.0819 - acc: 0.9725 - val_loss: 0.7971 - val_acc: 0.7950\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.0750 - acc: 0.9708 - val_loss: 0.8904 - val_acc: 0.7725\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 1s 756us/step - loss: 0.0527 - acc: 0.9792 - val_loss: 0.8123 - val_acc: 0.8125\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.0408 - acc: 0.9858 - val_loss: 0.8653 - val_acc: 0.8100\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 1s 751us/step - loss: 0.0356 - acc: 0.9875 - val_loss: 0.9868 - val_acc: 0.7900\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 1s 739us/step - loss: 0.0344 - acc: 0.9875 - val_loss: 1.0349 - val_acc: 0.7875\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 1s 738us/step - loss: 0.0368 - acc: 0.9900 - val_loss: 0.8974 - val_acc: 0.7950\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.0328 - acc: 0.9875 - val_loss: 1.0090 - val_acc: 0.7875\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 1s 749us/step - loss: 0.0218 - acc: 0.9892 - val_loss: 1.3749 - val_acc: 0.7400\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 1s 746us/step - loss: 0.0296 - acc: 0.9908 - val_loss: 0.8858 - val_acc: 0.7925\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 1s 743us/step - loss: 0.0139 - acc: 0.9967 - val_loss: 0.9907 - val_acc: 0.8025\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 1s 742us/step - loss: 0.0129 - acc: 0.9950 - val_loss: 1.1531 - val_acc: 0.7775\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 1s 730us/step - loss: 0.0074 - acc: 0.9992 - val_loss: 1.0969 - val_acc: 0.7850\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 1.1181 - val_acc: 0.7975\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 1s 742us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 1.3613 - val_acc: 0.7775\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 1.0827 - val_acc: 0.7975\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 1s 745us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.8867 - val_acc: 0.8100\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 1s 750us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.9099 - val_acc: 0.8025\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.0037 - acc: 0.9983 - val_loss: 1.0350 - val_acc: 0.7850\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 1s 739us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.0463 - val_acc: 0.7900\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.7850\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 5.3573e-04 - acc: 1.0000 - val_loss: 1.2334 - val_acc: 0.7750\n",
      "Epoch 50/50\n",
      "1200/1200 [==============================] - 1s 772us/step - loss: 9.0984e-04 - acc: 1.0000 - val_loss: 1.3951 - val_acc: 0.7525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4cd25c6a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v1.fit(trn_conv_features, trn_labels,\n",
    "                                          batch_size=32, \n",
    "                                          epochs=50,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True, \n",
    "                                          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_value(classifier_model_v1.optimizer.lr, 0.001)\n",
    "K.eval(classifier_model_v1.optimizer.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fully conv network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nf = 128\n",
    "p = 0. # adding any dropout at all means it doesnt train at all\n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v2 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v2.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(classifier_model_v1.optimizer.lr, 0.001)\n",
    "K.eval(classifier_model_v1.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 0s 302us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9275 - val_acc: 0.7725\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 0s 288us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1152 - val_acc: 0.7350\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 0s 284us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0190 - val_acc: 0.7650\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 0s 283us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.7775\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 0s 287us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.0824 - val_acc: 0.7575\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 0s 289us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2013 - val_acc: 0.7375\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 0s 286us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.1072 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 0s 288us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.0968 - val_acc: 0.7750\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 0s 284us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.1022 - val_acc: 0.7725\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 0s 285us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.7675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bc68ebda0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v2.fit(trn_conv_features, trn_labels, \n",
    "                                          batch_size=64, \n",
    "                                          epochs=10,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 128)         589952    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 2)           2306      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 592,258\n",
      "Trainable params: 592,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nf = 128\n",
    "p = 0. # adding any dropout at all means it doesnt train at all\n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "\n",
    "# x = MaxPooling2D((1,2))(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v3 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v3.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9999997e-06"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(classifier_model_v3.optimizer.lr, 0.00001)\n",
    "K.eval(classifier_model_v3.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - acc: 0.9933 - val_loss: 0.5148 - val_acc: 0.7400\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1083 - acc: 0.9942 - val_loss: 0.5213 - val_acc: 0.7350\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0976 - acc: 0.9967 - val_loss: 0.5166 - val_acc: 0.7325\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0876 - acc: 0.9975 - val_loss: 0.5187 - val_acc: 0.7375\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - acc: 0.9983 - val_loss: 0.5202 - val_acc: 0.7375\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0717 - acc: 0.9992 - val_loss: 0.5219 - val_acc: 0.7400\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0657 - acc: 1.0000 - val_loss: 0.5230 - val_acc: 0.7425\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0591 - acc: 0.9992 - val_loss: 0.5342 - val_acc: 0.7450\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.5290 - val_acc: 0.7400\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.5339 - val_acc: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9bff62e8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v3.fit(trn_conv_features, trn_labels, \n",
    "                                          batch_size=64, \n",
    "                                          epochs=10,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
