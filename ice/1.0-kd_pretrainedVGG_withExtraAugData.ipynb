{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import and base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '/home/ubuntu/data/iceberg'\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precompute conv layers for speed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13200 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/iceberg/pngs/trainWithAug',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=30,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/iceberg/pngs/valid',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=20,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_precomputed_data(model, generator):\n",
    "    filenames = generator.filenames\n",
    "    conv_features = model.predict_generator(generator, (generator.n/generator.batch_size))\n",
    "    labels_onehot = to_categorical(generator.classes)\n",
    "    labels = generator.classes\n",
    "    return (filenames, conv_features, labels_onehot, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_filenames, trn_conv_features, trn_labels, trn_labels_1 = create_precomputed_data(vgg_base, train_generator)\n",
    "val_filenames, val_conv_features, val_labels, val_labels_1 = create_precomputed_data(vgg_base, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(trn_filenames) == 13200, \"trn_filenames not as expected\"\n",
    "assert trn_conv_features.shape == (13200, 7, 7, 512), \"trn_conv_features not as expected\"\n",
    "assert trn_labels.shape == (13200, 2), \"trn_labels not as expected\"\n",
    "\n",
    "assert len(val_filenames) == 400, \"val_filenames not as expected\"\n",
    "assert val_conv_features.shape == (400, 7, 7, 512), \"val_conv_features not as expected\"\n",
    "assert val_labels.shape == (400, 2), \"val_labels not as expected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/ubuntu/data/iceberg/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_precomputed_data(filenames, conv_feats, labels, features_base_name=\"VGG16_conv_feats_with_aug/trn_\"):\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat', np.array(filenames))\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat', conv_feats)\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat', np.array(labels))\n",
    "    \n",
    "save_precomputed_data(trn_filenames, trn_conv_features, trn_labels, \"VGG16_conv_feats_with_aug/trn_\")\n",
    "save_precomputed_data(val_filenames, val_conv_features, val_labels, \"VGG16_conv_feats_with_aug/val_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_precomputed_data(features_base_name=\"VGG16_conv_feats_with_aug/trn_\"):\n",
    "    filenames = load_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat').tolist()\n",
    "    conv_feats = load_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat')\n",
    "    labels = load_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat')\n",
    "    return filenames, conv_feats, labels\n",
    "\n",
    "trn_filenames, trn_conv_features, trn_labels = load_precomputed_data(\"VGG16_conv_feats_with_aug/trn_\")\n",
    "val_filenames, val_conv_features, val_labels = load_precomputed_data(\"VGG16_conv_feats_with_aug/val_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_input_shape = (7, 7, 512)\n",
    "classifier_input = Input(shape=classifier_input_shape)\n",
    "\n",
    "nf = 128\n",
    "p = 0. # adding any dropout at all means it doesnt train at all\n",
    "\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = Dropout(p)(x)\n",
    "x = Conv2D(2,(3,3), padding='same')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v2 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v2.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_value(classifier_model_v2.optimizer.lr, 0.001)\n",
    "K.eval(classifier_model_v2.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13200 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "13200/13200 [==============================] - 3s 238us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7468 - val_acc: 0.8325\n",
      "Epoch 2/10\n",
      "13200/13200 [==============================] - 3s 227us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8300\n",
      "Epoch 3/10\n",
      "13200/13200 [==============================] - 3s 227us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7912 - val_acc: 0.8350\n",
      "Epoch 4/10\n",
      "13200/13200 [==============================] - 3s 226us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8120 - val_acc: 0.8300\n",
      "Epoch 5/10\n",
      "13200/13200 [==============================] - 3s 222us/step - loss: 8.4659e-04 - acc: 1.0000 - val_loss: 0.8224 - val_acc: 0.8275\n",
      "Epoch 6/10\n",
      "13200/13200 [==============================] - 3s 224us/step - loss: 7.0729e-04 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.8300\n",
      "Epoch 7/10\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 6.0155e-04 - acc: 1.0000 - val_loss: 0.8399 - val_acc: 0.8250\n",
      "Epoch 8/10\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 4.7420e-04 - acc: 1.0000 - val_loss: 0.8501 - val_acc: 0.8275\n",
      "Epoch 9/10\n",
      "13200/13200 [==============================] - 3s 224us/step - loss: 4.1687e-04 - acc: 1.0000 - val_loss: 0.8773 - val_acc: 0.8250\n",
      "Epoch 10/10\n",
      "13200/13200 [==============================] - 3s 225us/step - loss: 3.6751e-04 - acc: 1.0000 - val_loss: 0.8724 - val_acc: 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f961e201080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model_v2.fit(trn_conv_features, trn_labels, \n",
    "                                          batch_size=64, \n",
    "                                          epochs=10,\n",
    "                                          validation_data=(val_conv_features, val_labels),\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_v2.save('/home/ubuntu/data/iceberg/results/weights/VGG16_plus_simplev2_1train_08val.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
