{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the geotiff with rasterio\n",
    "# copy the channel as 3 channels, \n",
    "# make a png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conver the tif files to png, this code sort the scaling, tried imagemagick convert but it the images were all black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "\n",
    "root_folder = '/home/ubuntu/data/sar/train/train_3classes_240/other/'\n",
    "for filename in os.listdir (root_folder):\n",
    "    data_path = os.path.join(root_folder, filename)\n",
    "\n",
    "    with rasterio.open(data_path) as raster:\n",
    "        img_array = raster.read(1)\n",
    "    count +=1\n",
    "#     plt.imshow(img_array)\n",
    "#     plt.show()\n",
    "    png_path = data_path.replace('.tif', '.png')\n",
    "    scipy.misc.imsave(png_path, img_array)\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/sar/train/train_3classes_140/oil_platform\n"
     ]
    }
   ],
   "source": [
    "# # used to make the validation data - commented so do not run again. \n",
    "\n",
    "import glob\n",
    "from shutil import move\n",
    "from shutil import copyfile\n",
    "\n",
    "%cd /home/ubuntu/data/sar/train/train_3classes_140/oil_platform/ \n",
    "g = glob.glob('*.png')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(30): copyfile(shuf[i], '/home/ubuntu/data/sar/train/sample_240/valid/' +'/turbine/' + shuf[i])\n",
    "# for i in range(200): move(shuf[i], '/home/ubuntu/data/sar/train/valid_3classes_140' +'/oil_platform/' + shuf[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually removed the following files to make the numbers nicer for the batching \n",
    "S1A_IW_GRDH_1SDV_20170214T062124_20170214T062149_015276_019087_AF6B_terrain_correction_9.png            \n",
    "S1A_IW_GRDH_1SDV_20170214T062124_20170214T062149_015276_019087_AF6B_terrain_correction_9_rot180.png     \n",
    "S1A_IW_GRDH_1SDV_20170214T062124_20170214T062149_015276_019087_AF6B_terrain_correction_9_rot90.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the base model of vgg and precompute the convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Flatten\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for l in base_model.layers:\n",
    "    l.trainable =False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4420 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#     rescale=1./255)\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/sar/train/train_3classes_240',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/data/sar/train/valid_3classes_240', \n",
    "        target_size=(224, 224),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rgb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next.im_self.color_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2cc739290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/ubuntu/data/sar/train/valid_3classes_240/other/S1A_IW_GRDH_1SDV_20170214T062124_20170214T062149_015276_019087_AF6B_terrain_correction_2.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def preprocess_input(x, data_format=None):\n",
    "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: input Numpy tensor, 4D.\n",
    "        data_format: data format of the image tensor.\n",
    "    # Returns\n",
    "        Preprocessed tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    # Zero-center by mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_precomputed_data(model, batches):\n",
    "    filenames = batches.filenames\n",
    "    conv_features = model.predict_generator(batches, (batches.samples / batches.batch_size), verbose=1)\n",
    "    labels_onehot = to_categorical(batches.classes)\n",
    "    labels = batches.classes\n",
    "    return (filenames, conv_features, labels_onehot, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 3588s  \n",
      "60/60 [==============================] - 488s   \n"
     ]
    }
   ],
   "source": [
    "trn_filenames, trn_conv_features, trn_labels, trn_labels_1 = create_precomputed_data(base_model, train_generator)\n",
    "val_filenames, val_conv_features, val_labels, val_labels_1 = create_precomputed_data(base_model, validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4420, 7, 7, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_conv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/ubuntu/data/sar/train/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_precomputed_data(filenames, conv_feats, labels, features_base_name=\"VGG240crops_conv_feats/trn_\"):\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat', np.array(filenames))\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat', conv_feats)\n",
    "    save_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat', np.array(labels))\n",
    "    \n",
    "save_precomputed_data(trn_filenames, trn_conv_features, trn_labels, \"VGG240crops_conv_feats/trn_\")\n",
    "save_precomputed_data(val_filenames, val_conv_features, val_labels, \"VGG240crops_conv_feats/val_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_precomputed_data(features_base_name=\"VGG240crops_conv_feats/trn_\"):\n",
    "    filenames = load_array(RESULTS_DIR+\"/\"+features_base_name+'filenames.dat').tolist()\n",
    "    conv_feats = load_array(RESULTS_DIR+\"/\"+features_base_name+'conv_feats.dat')\n",
    "    labels = load_array(RESULTS_DIR+\"/\"+features_base_name+'labels.dat')\n",
    "    return filenames, conv_feats, labels\n",
    "\n",
    "trn_filenames, trn_conv_features, trn_labels = load_precomputed_data(\"VGG240crops_conv_feats/trn_\")\n",
    "val_filenames, val_conv_features, val_labels = load_precomputed_data(\"VGG240crops_conv_feats/val_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, BatchNormalization, Dense, Dropout, Conv2D\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from datetime import datetime\n",
    "import distutils.dir_util\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "p=0.7\n",
    "classifier_input_shape = (7, 7, 512)\n",
    "# classifier_input_shape = resnet_base.layers[-1].output_shape[1:]\n",
    "classifier_input = Input(shape=classifier_input_shape)\n",
    "\n",
    "# Create classifier model\n",
    "      \n",
    "x = Flatten()(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(p/4)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "                                                     \n",
    "classifier_model_v1 = Model(classifier_input, x)\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "classifier_model_v1.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25088)             100352    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 13,214,211\n",
      "Trainable params: 13,161,987\n",
      "Non-trainable params: 52,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_precomputed_helper(model, result_dir_name, lr=0.1, nb_epoch=1):  \n",
    "    K.set_value(model.optimizer.lr, lr)\n",
    "    \n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S.h5\")\n",
    "    results_dir = RESULTS_DIR + \"/\" + result_dir_name + \"/\"\n",
    "    distutils.dir_util.mkpath(results_dir)\n",
    "    \n",
    "    model.fit(trn_conv_features, trn_labels,\n",
    "              batch_size=32, \n",
    "              epochs=nb_epoch,\n",
    "              validation_data=(val_conv_features, val_labels),\n",
    "              shuffle=True, \n",
    "              callbacks=[CSVLogger(results_dir+\"epoch_results.csv\", separator=',', append=True)])\n",
    "    model.save_weights(results_dir + now)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4420 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "3264/4420 [=====================>........] - ETA: 8s - loss: 1.8236 - acc: 0.3928"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-869ac6dccbe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier_model_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_precomputed_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classifier_model_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-c454e2659181>\u001b[0m in \u001b[0;36mfit_precomputed_helper\u001b[0;34m(model, result_dir_name, lr, nb_epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_conv_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m               callbacks=[CSVLogger(results_dir+\"epoch_results.csv\", separator=',', append=True)])\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier_model_v1 = fit_precomputed_helper(classifier_model_v1, \"classifier_model_v1\", lr=0.0001, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_model_v1.save_weights('/home/ubuntu/git/learningWithKaggle/weights/fishing/ft_resnet93_valid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf = 128\n",
    "p = 0.4\n",
    "\n",
    "# x = Flatten(input_shape=classifier_input_shape)(classifier_input)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "# x = MaxPooling2D((1,2))(x)\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "classifier_model_v2 = Model(classifier_input, x)\n",
    "\n",
    "classifier_model_v2.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4420 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "4420/4420 [==============================] - 28s - loss: 1.0589 - acc: 0.4613 - val_loss: 1.1881 - val_acc: 0.3167\n",
      "Epoch 2/10\n",
      "4420/4420 [==============================] - 28s - loss: 1.0341 - acc: 0.4729 - val_loss: 1.1866 - val_acc: 0.3350\n",
      "Epoch 3/10\n",
      "4420/4420 [==============================] - 28s - loss: 1.0287 - acc: 0.4756 - val_loss: 1.1648 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "4420/4420 [==============================] - 28s - loss: 1.0045 - acc: 0.4837 - val_loss: 1.1489 - val_acc: 0.3300\n",
      "Epoch 5/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.9806 - acc: 0.5104 - val_loss: 1.2446 - val_acc: 0.3283\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.9262 - acc: 0.5369 - val_loss: 1.2550 - val_acc: 0.3283\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.8726 - acc: 0.5622 - val_loss: 1.2657 - val_acc: 0.3367\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.8058 - acc: 0.6048 - val_loss: 1.2978 - val_acc: 0.3300\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.7322 - acc: 0.6443 - val_loss: 1.4829 - val_acc: 0.3233\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 28s - loss: 0.6681 - acc: 0.6842 - val_loss: 1.4482 - val_acc: 0.2967\n"
     ]
    }
   ],
   "source": [
    "classifier_model_v2 = fit_precomputed_helper(classifier_model_v2, \"classifier_model_v2\", lr=0.0001, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create classifier model\n",
    "\n",
    "x= Flatten()(classifier_input)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "                                                     \n",
    "classifier_model_v3 = Model(classifier_input, x)\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "classifier_model_v3.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4420 samples, validate on 600 samples\n",
      "Epoch 1/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.0087 - acc: 0.7586 - val_loss: 4.8310 - val_acc: 0.2433\n",
      "Epoch 2/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.8931 - acc: 0.7792 - val_loss: 6.3098 - val_acc: 0.2933\n",
      "Epoch 3/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.6226 - acc: 0.7471 - val_loss: 3.9133 - val_acc: 0.2950\n",
      "Epoch 4/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.4037 - acc: 0.7817 - val_loss: 4.8687 - val_acc: 0.2533\n",
      "Epoch 5/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9947 - acc: 0.7803 - val_loss: 5.9887 - val_acc: 0.2283\n",
      "Epoch 6/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.2995 - acc: 0.7633 - val_loss: 5.5498 - val_acc: 0.2633\n",
      "Epoch 7/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.3528 - acc: 0.7851 - val_loss: 4.4832 - val_acc: 0.3317\n",
      "Epoch 8/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9373 - acc: 0.8276 - val_loss: 4.2178 - val_acc: 0.4183\n",
      "Epoch 9/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.8873 - acc: 0.8215 - val_loss: 5.5758 - val_acc: 0.2717\n",
      "Epoch 10/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.0311 - acc: 0.8066 - val_loss: 4.8132 - val_acc: 0.4333\n",
      "Epoch 11/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.1236 - acc: 0.7839 - val_loss: 4.6127 - val_acc: 0.3767\n",
      "Epoch 12/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9941 - acc: 0.8131 - val_loss: 4.2415 - val_acc: 0.4150\n",
      "Epoch 13/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.4571 - acc: 0.7722 - val_loss: 6.9169 - val_acc: 0.2667\n",
      "Epoch 14/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.0536 - acc: 0.8057 - val_loss: 6.7247 - val_acc: 0.3300\n",
      "Epoch 15/50\n",
      "4420/4420 [==============================] - 0s - loss: 1.0155 - acc: 0.8011 - val_loss: 6.8266 - val_acc: 0.2333\n",
      "Epoch 16/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9500 - acc: 0.8299 - val_loss: 5.8626 - val_acc: 0.3083\n",
      "Epoch 17/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.8316 - acc: 0.8446 - val_loss: 5.8738 - val_acc: 0.3017\n",
      "Epoch 18/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.8459 - acc: 0.8518 - val_loss: 5.7990 - val_acc: 0.2967\n",
      "Epoch 19/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.8795 - acc: 0.8459 - val_loss: 6.2812 - val_acc: 0.3100\n",
      "Epoch 20/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9219 - acc: 0.8441 - val_loss: 7.1398 - val_acc: 0.3100\n",
      "Epoch 21/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9152 - acc: 0.8432 - val_loss: 5.8045 - val_acc: 0.3633\n",
      "Epoch 22/50\n",
      "4420/4420 [==============================] - 0s - loss: 0.9537 - acc: 0.8475 - val_loss: 6.2183 - val_acc: 0.3017\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e694d0d66e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier_model_v3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_precomputed_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classifier_model_v3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-c454e2659181>\u001b[0m in \u001b[0;36mfit_precomputed_helper\u001b[0;34m(model, result_dir_name, lr, nb_epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_conv_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m               callbacks=[CSVLogger(results_dir+\"epoch_results.csv\", separator=',', append=True)])\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier_model_v3 = fit_precomputed_helper(classifier_model_v3, \"classifier_model_v3\", lr=0.001, nb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
