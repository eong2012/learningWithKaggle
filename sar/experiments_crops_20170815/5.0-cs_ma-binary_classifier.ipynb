{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "0.19.1\n",
      "2.0.0\n",
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print kv\n",
    "print sv\n",
    "print mv\n",
    "print nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'utils.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert tif2png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in 1.1-mph_as_kd-baseline-simple_CNN_from_scratch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple/baseline model (3 layers, no regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9217      \n",
      "=================================================================\n",
      "Total params: 64,961\n",
      "Trainable params: 64,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 10s - loss: 0.3257 - acc: 0.8729 - val_loss: 0.2315 - val_acc: 0.9316\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 11s - loss: 0.2011 - acc: 0.9284 - val_loss: 0.1805 - val_acc: 0.9416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3afca5ea90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 11s - loss: 0.1532 - acc: 0.9494 - val_loss: 0.2937 - val_acc: 0.9449\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 13s - loss: 0.1446 - acc: 0.9515 - val_loss: 0.4490 - val_acc: 0.8230\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 13s - loss: 0.1185 - acc: 0.9589 - val_loss: 0.2916 - val_acc: 0.9165\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 12s - loss: 0.1070 - acc: 0.9594 - val_loss: 0.3027 - val_acc: 0.9264\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 11s - loss: 0.1111 - acc: 0.9585 - val_loss: 0.1896 - val_acc: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a9c14e950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 10s - loss: 0.0526 - acc: 0.9800 - val_loss: 0.1681 - val_acc: 0.9533\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 13s - loss: 0.0562 - acc: 0.9769 - val_loss: 0.1480 - val_acc: 0.9549\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 14s - loss: 0.0408 - acc: 0.9855 - val_loss: 0.1621 - val_acc: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a9c14ef50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 10s - loss: 0.0502 - acc: 0.9809 - val_loss: 0.1773 - val_acc: 0.9565\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 11s - loss: 0.0462 - acc: 0.9825 - val_loss: 0.1396 - val_acc: 0.9583\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 11s - loss: 0.0503 - acc: 0.9795 - val_loss: 0.1620 - val_acc: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a9c14e7d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 11s - loss: 0.0463 - acc: 0.9849 - val_loss: 0.1548 - val_acc: 0.9516\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 11s - loss: 0.0404 - acc: 0.9839 - val_loss: 0.1392 - val_acc: 0.9549: 2s - lo - ETA: 0s - loss: 0.0406 - acc: 0.98\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 11s - loss: 0.0365 - acc: 0.9875 - val_loss: 0.1667 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a9c14e690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip = True\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                  horizontal_flip = True\n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation parameters notes\n",
    "    - rotation_range (0 to 180): performs poorly, struggles to reach 80% accuracy on training set and underfits\n",
    "    - vertical_flip (True): also not great, stalls around 70% accuracy on training set\n",
    "    - horizontal_flip (True): excellent! ... although, it seems a model with *no* augmentations also hits 97.5% quite quickly...\n",
    "    - width_shift_range, height_shift_range: very slow to exceed 60% on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9217      \n",
      "=================================================================\n",
      "Total params: 64,961\n",
      "Trainable params: 64,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 15s - loss: 0.4437 - acc: 0.8369 - val_loss: 0.3890 - val_acc: 0.8982\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 12s - loss: 0.2904 - acc: 0.9028 - val_loss: 0.3666 - val_acc: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4a3e0b10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 12s - loss: 0.2387 - acc: 0.9148 - val_loss: 0.2458 - val_acc: 0.9466\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 12s - loss: 0.2036 - acc: 0.9293 - val_loss: 0.2379 - val_acc: 0.9249.2410 - a - ETA: 5s - loss: 0.2260 - acc:  - ETA: 4s - l - ETA: 1s - loss: 0.2063 \n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 11s - loss: 0.1754 - acc: 0.9351 - val_loss: 0.2064 - val_acc: 0.9399\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 12s - loss: 0.1845 - acc: 0.9438 - val_loss: 0.1719 - val_acc: 0.9448\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 12s - loss: 0.1351 - acc: 0.9496 - val_loss: 0.2694 - val_acc: 0.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4a8bf410>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 11s - loss: 0.1503 - acc: 0.9485 - val_loss: 0.1506 - val_acc: 0.9533\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 11s - loss: 0.1313 - acc: 0.9505 - val_loss: 0.2374 - val_acc: 0.9249.9\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 11s - loss: 0.1239 - acc: 0.9599 - val_loss: 0.1486 - val_acc: 0.9549\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 12s - loss: 0.1152 - acc: 0.9600 - val_loss: 0.2089 - val_acc: 0.9516\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 11s - loss: 0.1099 - acc: 0.9585 - val_loss: 0.1498 - val_acc: 0.9466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4a2c7ad0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 13s - loss: 0.0671 - acc: 0.9770 - val_loss: 0.1716 - val_acc: 0.9516\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 11s - loss: 0.0625 - acc: 0.9774 - val_loss: 0.1461 - val_acc: 0.9548: 0s - loss: 0.0599 - acc: \n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 11s - loss: 0.0590 - acc: 0.9800 - val_loss: 0.1438 - val_acc: 0.9516.9\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 11s - loss: 0.0611 - acc: 0.9768 - val_loss: 0.1317 - val_acc: 0.9633\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 12s - loss: 0.0529 - acc: 0.9810 - val_loss: 0.1504 - val_acc: 0.9533s - loss: 0.0491 - acc: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4a8a7b90>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 11s - loss: 0.0516 - acc: 0.9830 - val_loss: 0.1454 - val_acc: 0.9533\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 11s - loss: 0.0564 - acc: 0.9795 - val_loss: 0.1682 - val_acc: 0.9565 ETA: 8s - - ETA: 5s -  - ETA: 3s - los - ETA: 0s - loss: 0.0563 - acc:\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 11s - loss: 0.0457 - acc: 0.9819 - val_loss: 0.1492 - val_acc: 0.9533\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 11s - loss: 0.0480 - acc: 0.9845 - val_loss: 0.1548 - val_acc: 0.9599\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 11s - loss: 0.0566 - acc: 0.9810 - val_loss: 0.1457 - val_acc: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4a8a7f50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip = True\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                  horizontal_flip = True\n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9217      \n",
      "=================================================================\n",
      "Total params: 64,961\n",
      "Trainable params: 64,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# With data augmentation?\n",
    "classifier_input = Input(shape=input_shapeape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 21s - loss: 3.3670 - acc: 0.7031 - val_loss: 2.7359 - val_acc: 0.8147\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 21s - loss: 4.6702 - acc: 0.7009 - val_loss: 8.0994 - val_acc: 0.4975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a4b9cf050>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Layers + dropout\n",
    "Note: adding dropout (of whatever value for p) doesn't seem to help much - p = 0.3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255\n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 12, 12, 3)         1731      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 132,532\n",
      "Trainable params: 132,148\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3,3,3, border_mode='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 20s - loss: 8.0571 - acc: 0.5001 - val_loss: 8.9067 - val_acc: 0.4474\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 20s - loss: 8.0913 - acc: 0.4980 - val_loss: 8.5981 - val_acc: 0.4666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e63c2c10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 1.1843 - acc: 0.9240 - val_loss: 1.0469 - val_acc: 0.9332\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.9541 - acc: 0.9359 - val_loss: 1.1619 - val_acc: 0.9231\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 20s - loss: 1.2411 - acc: 0.9188 - val_loss: 1.3336 - val_acc: 0.9132\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 1.0973 - acc: 0.9270 - val_loss: 0.9836 - val_acc: 0.9366\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 20s - loss: 1.0124 - acc: 0.9331 - val_loss: 1.2159 - val_acc: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e63cb090>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 44s - loss: 0.0253 - acc: 0.9905 - val_loss: 0.1226 - val_acc: 0.9683\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 42s - loss: 0.0074 - acc: 0.9975 - val_loss: 0.1323 - val_acc: 0.9716\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 43s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.1122 - val_acc: 0.9716\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 42s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.1365 - val_acc: 0.9749\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 44s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0986 - val_acc: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e6a7c050>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 43s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.1278 - val_acc: 0.9750\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 43s - loss: 0.0051 - acc: 0.9990 - val_loss: 0.1314 - val_acc: 0.9750\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 44s - loss: 0.0023 - acc: 0.9990 - val_loss: 0.1292 - val_acc: 0.9800\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 43s - loss: 0.0044 - acc: 0.9990 - val_loss: 0.1530 - val_acc: 0.9682\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 43s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1150 - val_acc: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e6a7bf90>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_dropout_p_0p3_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More layers, no augmentation - turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 12, 12, 3)         1731      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 132,532\n",
      "Trainable params: 132,148\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3,3,3, border_mode='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 20s - loss: 0.3208 - acc: 0.8874 - val_loss: 0.6734 - val_acc: 0.4808\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 25s - loss: 0.1456 - acc: 0.9475 - val_loss: 0.6320 - val_acc: 0.5242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ec519310>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 29s - loss: 0.1179 - acc: 0.9559 - val_loss: 0.3605 - val_acc: 0.8545\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 43s - loss: 0.0891 - acc: 0.9689 - val_loss: 0.2147 - val_acc: 0.9199\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 40s - loss: 0.0889 - acc: 0.9695 - val_loss: 0.0998 - val_acc: 0.9666\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0687 - acc: 0.9710 - val_loss: 0.1358 - val_acc: 0.9498\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 20s - loss: 0.0501 - acc: 0.9770 - val_loss: 0.1047 - val_acc: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ed62ec90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.0386 - acc: 0.9870 - val_loss: 0.3639 - val_acc: 0.9082\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.0446 - acc: 0.9854 - val_loss: 0.1265 - val_acc: 0.9616\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 20s - loss: 0.0298 - acc: 0.9930 - val_loss: 0.1316 - val_acc: 0.9750\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0332 - acc: 0.9890 - val_loss: 0.1597 - val_acc: 0.9565\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 20s - loss: 0.0190 - acc: 0.9920 - val_loss: 0.1166 - val_acc: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f410df29d50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 35s - loss: 0.0048 - acc: 0.9980 - val_loss: 0.1326 - val_acc: 0.9666\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 51s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9766\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 51s - loss: 4.8901e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9800\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 51s - loss: 4.4534e-04 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9732\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 50s - loss: 1.5490e-04 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ed62e190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 1.3475e-04 - acc: 1.0000 - val_loss: 0.1647 - val_acc: 0.9716\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 6.1550e-05 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9783\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 20s - loss: 3.4565e-05 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9766\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 2.0029e-05 - acc: 1.0000 - val_loss: 0.1780 - val_acc: 0.9783\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 20s - loss: 1.1744e-05 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ec33ced0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/validate/50x50/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 12, 12, 3)         1731      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 132,532\n",
      "Trainable params: 132,148\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:10: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3,3,3, border_mode='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.3215 - acc: 0.8869 - val_loss: 0.9744 - val_acc: 0.3506\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.1669 - acc: 0.9345 - val_loss: 0.8207 - val_acc: 0.2638\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 19s - loss: 0.1110 - acc: 0.9610 - val_loss: 0.5398 - val_acc: 0.7140\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0816 - acc: 0.9705 - val_loss: 0.2143 - val_acc: 0.9533\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s - loss: 0.0631 - acc: 0.9805 - val_loss: 0.1715 - val_acc: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e99d53d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.0209 - acc: 0.9925 - val_loss: 0.1408 - val_acc: 0.9583\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 19s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.1130 - val_acc: 0.9649\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 20s - loss: 0.0105 - acc: 0.9980 - val_loss: 0.1333 - val_acc: 0.9632\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0063 - acc: 0.9985 - val_loss: 0.1031 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 20s - loss: 0.0056 - acc: 0.9990 - val_loss: 0.1418 - val_acc: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ec2f5490>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.0034 - acc: 0.9990 - val_loss: 0.1402 - val_acc: 0.9716\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1442 - val_acc: 0.9716\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 19s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1688 - val_acc: 0.9666\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9750\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e859bb10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/oil_binary_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/validate/50x50/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1988 images belonging to 2 classes.\n",
      "Found 497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 12, 12, 3)         1731      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 132,532\n",
      "Trainable params: 132,148\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:10: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: UserWarning:\n",
      "\n",
      "Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.1\n",
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3,3,3, border_mode='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=classifier_input)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 22s - loss: 0.5329 - acc: 0.7982 - val_loss: 0.6243 - val_acc: 0.7290\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 21s - loss: 0.2816 - acc: 0.8803 - val_loss: 0.5505 - val_acc: 0.8509\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 21s - loss: 0.2058 - acc: 0.9125 - val_loss: 0.5068 - val_acc: 0.7588\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 21s - loss: 0.1610 - acc: 0.9405 - val_loss: 0.2620 - val_acc: 0.9363\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 21s - loss: 0.1260 - acc: 0.9545 - val_loss: 0.1912 - val_acc: 0.9246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e6c97f90>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.1203 - acc: 0.9533 - val_loss: 0.2970 - val_acc: 0.9125\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.1020 - acc: 0.9608 - val_loss: 1.4783 - val_acc: 0.5946\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 20s - loss: 0.0810 - acc: 0.9745 - val_loss: 0.1372 - val_acc: 0.9564\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 19s - loss: 0.0593 - acc: 0.9775 - val_loss: 0.0940 - val_acc: 0.9631\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s - loss: 0.0569 - acc: 0.9770 - val_loss: 0.1556 - val_acc: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e6f01ed0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 20s - loss: 0.0172 - acc: 0.9955 - val_loss: 0.1209 - val_acc: 0.9663\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s - loss: 0.0088 - acc: 0.9975 - val_loss: 0.1082 - val_acc: 0.9698\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 19s - loss: 0.0063 - acc: 0.9990 - val_loss: 0.1314 - val_acc: 0.9581\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 19s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0887 - val_acc: 0.9765\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s - loss: 0.0030 - acc: 0.9995 - val_loss: 0.1204 - val_acc: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e6a55d10>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 19s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.2088 - val_acc: 0.9495\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 19s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1116 - val_acc: 0.9732\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 19s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9782\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 20s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9732\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s - loss: 9.9364e-04 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40e7973a10>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/other_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets visualise and evaluate/plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_generator(validation_generator,50)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other', 'turbine']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(validation_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[249   0]\n",
      " [250   0]]\n"
     ]
    }
   ],
   "source": [
    "y_true = validation_generator.classes\n",
    "labels = [0,1] # sorted(list(validation_generator.class_indices))\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred, labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[249   0]\n",
      " [250   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nomuIpOgGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a84106a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a681dfb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_confusion_matrix(cm, sorted(list(validation_generator.class_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 'oil_and_gas_infrastructure' false positives = 250\n",
      "Number 'turbine' false positives = 0\n",
      "\n",
      "\n",
      "Number 'oil_and_gas_infrastructure' false negatives = 0\n",
      "Number 'turbine' false negatives = 0\n"
     ]
    }
   ],
   "source": [
    "# Number false positives = sum vertical (non-diagonal) rows =\n",
    "print \"Number 'oil_and_gas_infrastructure' false positives = {}\".format(sum(cm[1:,0]))\n",
    "print \"Number 'turbine' false positives = {}\".format(sum(cm[:2,2]))\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "# Number false negatives = sum horizontal (non-diagonal) rows =\n",
    "print \"Number 'oil_and_gas_infrastructure' false negatives = {}\".format(sum(cm[0, 1:]))\n",
    "print \"Number 'turbine' false negatives = {}\".format(sum(cm[2, :2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce filenames for kari_plot\n",
    "short_validation_filenames = [name[-35:] for name in validation_generator.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-920b6545294e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkari_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_validation_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/git/learningWithKaggle/sar/experiments_crops_20170815/utils.pyc\u001b[0m in \u001b[0;36mkari_plot\u001b[0;34m(preds, short_validation_filenames)\u001b[0m\n\u001b[1;32m    235\u001b[0m     other_probs = go.Bar(\n\u001b[1;32m    236\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'other'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshort_validation_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "utils.kari_plot(preds, short_validation_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see good predictions on the whole:\n",
    "\n",
    " - Some actual `oil_and_gas_infrastructure` is being predicted as `other` (i.e. false negatives).\n",
    " - Some actual `turbine` is being predicted as `other` (i.e. false negatives).\n",
    " - Many `other` is being predicted as `turbine`/`oil_and_gas_infrastructure` (i.e. false positives).\n",
    " \n",
    " \n",
    "Lets break the Kari plot into each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Actual \"oil_and_gas_infrastructure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.kari_plot(preds[:125,], short_validation_filenames[:125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.display_random_good_prediction(preds[:125,],\n",
    "                                    validation_generator.filenames[:125],\n",
    "                                    valid_dir,\n",
    "                                    0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_bad_prediction(preds[:125,],\n",
    "                                    validation_generator.filenames[:125],\n",
    "                                    valid_dir,\n",
    "                                    0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_uncertain_prediction(preds[:125,],\n",
    "                                    validation_generator.filenames[:125],\n",
    "                                    valid_dir,\n",
    "                                    0,\n",
    "                                    0.7,\n",
    "                                    0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMARKS: Good predictions all appear consist of quite large blobs, bad predictions appear to consist of quite small blobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Actual \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.kari_plot(preds[125:250], short_validation_filenames[125:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.display_random_good_prediction(preds[125:250,],\n",
    "                                    validation_generator.filenames[125:250],\n",
    "                                    valid_dir,\n",
    "                                    1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_bad_prediction(preds[125:250,],\n",
    "                                    validation_generator.filenames[125:250],\n",
    "                                    valid_dir,\n",
    "                                    1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_uncertain_prediction(preds[125:250,],\n",
    "                                    validation_generator.filenames[125:250],\n",
    "                                    valid_dir,\n",
    "                                    1,\n",
    "                                    0.7,\n",
    "                                    0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMARKS: Bad predictions all appear consist of quite large blobs (confused and `oil_and_gas_infrastructure`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kari Plot \"turbine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.kari_plot(preds[250:], short_validation_filenames[250:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.display_random_good_prediction(preds[250:,],\n",
    "                                    validation_generator.filenames[250:],\n",
    "                                    valid_dir,\n",
    "                                    2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_bad_prediction(preds[250:,],\n",
    "                                    validation_generator.filenames[250:],\n",
    "                                    valid_dir,\n",
    "                                    2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.display_random_uncertain_prediction(preds[250:,],\n",
    "                                    validation_generator.filenames[250:],\n",
    "                                    valid_dir,\n",
    "                                    2,\n",
    "                                    0.7,\n",
    "                                    0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMARK: Nothing really noticable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing model to deal with overfitting - batchnorm? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_batchnorm = Model(outputs=x, inputs=classifier_input)\n",
    "model_batchnorm.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_batchnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm.optimizer.lr, lr)\n",
    "model_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm.optimizer.lr, lr)\n",
    "model_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm.optimizer.lr, lr)\n",
    "model_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_batchnorm.optimizer.lr, lr)\n",
    "model_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move position of batchnorm? need to split the activation from the conv layer first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=None, padding='same')(classifier_input)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_split_activation = Model(outputs=x, inputs=classifier_input)\n",
    "model_split_activation.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_split_activation.optimizer.lr, lr)\n",
    "model_split_activation.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "K.set_value(model_split_activation.optimizer.lr, lr)\n",
    "model_split_activation.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add the batchnorm before the activation. (need dense layers mid way? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Conv2D(32, (3, 3), activation=None, padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_split_activation_batchnorm = Model(outputs=x, inputs=classifier_input)\n",
    "model_split_activation_batchnorm.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_split_activation_batchnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation accuracy is jumping around so we will try increasing the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=40,\n",
    "        class_mode='categorical', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator2 = test_datagen2.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_split_activation_batchnorm.optimizer.lr, lr)\n",
    "model_split_activation_batchnorm.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing model to include dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "p=0.6\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=None, padding='same')(classifier_input)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(p/4)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation=None, padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_batchnorm_dropout = Model(outputs=x, inputs=classifier_input)\n",
    "model_batchnorm_dropout.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally data augmentation (on pretrained best model = model_batchnorm_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen_aug = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "test_datagen_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=40,\n",
    "        class_mode='categorical', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator_aug = test_datagen_aug.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_batchnorm_dropout.optimizer.lr, lr)\n",
    "model_batchnorm_dropout.fit_generator(\n",
    "        train_generator2,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator2,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## More Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove me \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=10,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_dense = Model(outputs=x, inputs=classifier_input)\n",
    "model_dense.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_dense).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_dense.optimizer.lr, lr)\n",
    "model_dense.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
