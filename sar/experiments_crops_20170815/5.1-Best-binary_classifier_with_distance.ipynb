{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 50, 50, 32)    320         input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 12, 12, 64)    256         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 12, 12, 64)    256         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 12, 12, 64)    256         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 12, 12, 3)     0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 432)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 433)           0           flatten_8[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             434         merge_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.3219 - acc: 0.8808 - val_loss: 0.1907 - val_acc: 0.9459\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1721 - acc: 0.9314 - val_loss: 1.8712 - val_acc: 0.5050\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1591 - acc: 0.9464 - val_loss: 0.1064 - val_acc: 0.9619\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 22s - loss: 0.1119 - acc: 0.9589 - val_loss: 0.1018 - val_acc: 0.9719\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0998 - acc: 0.9614 - val_loss: 0.0856 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0789 - acc: 0.9689 - val_loss: 0.1000 - val_acc: 0.9659\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0723 - acc: 0.9729 - val_loss: 0.2282 - val_acc: 0.9399\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 36s - loss: 0.0512 - acc: 0.9795 - val_loss: 0.1038 - val_acc: 0.9659\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0472 - acc: 0.9825 - val_loss: 0.0940 - val_acc: 0.9739\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0488 - acc: 0.9820 - val_loss: 0.0977 - val_acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2fad0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0315 - acc: 0.9875 - val_loss: 0.0756 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0694 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0089 - acc: 0.9985 - val_loss: 0.0722 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0733 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 0.9820\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0038 - acc: 0.9995 - val_loss: 0.0838 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0852 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0897 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0914 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0908 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2f390>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 50, 50, 32)    320         input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 12, 12, 64)    256         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 12, 12, 64)    256         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 12, 12, 64)    256         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 12, 12, 3)     0           conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 432)           0           dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 433)           0           flatten_10[0][0]                 \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             434         merge_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.4501 - acc: 0.8101 - val_loss: 0.3883 - val_acc: 0.8236\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.2956 - acc: 0.8848 - val_loss: 0.2846 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2269 - acc: 0.9083 - val_loss: 0.7400 - val_acc: 0.6453\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2051 - acc: 0.9228 - val_loss: 0.3110 - val_acc: 0.8537\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1731 - acc: 0.9394 - val_loss: 0.1576 - val_acc: 0.9399\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1475 - acc: 0.9444 - val_loss: 0.1333 - val_acc: 0.9359\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1222 - acc: 0.9529 - val_loss: 0.1140 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.1117 - acc: 0.9619 - val_loss: 0.1221 - val_acc: 0.9579\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1015 - acc: 0.9574 - val_loss: 0.1980 - val_acc: 0.9359\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0740 - acc: 0.9719 - val_loss: 0.2228 - val_acc: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d95967d0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0572 - acc: 0.9775 - val_loss: 0.1134 - val_acc: 0.9639\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0313 - acc: 0.9875 - val_loss: 0.1252 - val_acc: 0.9599\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.1138 - val_acc: 0.9659\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0166 - acc: 0.9955 - val_loss: 0.1218 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.1245 - val_acc: 0.9679\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0163 - acc: 0.9945 - val_loss: 0.1114 - val_acc: 0.9699\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.1134 - val_acc: 0.9719\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 30s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.1138 - val_acc: 0.9699\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0082 - acc: 0.9985 - val_loss: 0.1180 - val_acc: 0.9719\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0097 - acc: 0.9975 - val_loss: 0.1282 - val_acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d9596f50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.1299 - val_acc: 0.9699\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.1321 - val_acc: 0.9639\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9719\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.1232 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0045 - acc: 0.9995 - val_loss: 0.1264 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 0.9995 - val_loss: 0.1344 - val_acc: 0.9619\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0040 - acc: 0.9995 - val_loss: 0.1201 - val_acc: 0.9699\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1208 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1281 - val_acc: 0.9659\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe82060b190>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 50, 50, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 12, 12, 3)     1731        batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 12, 12, 3)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 433)           0           flatten_1[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             434         merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.7732 - acc: 0.8126 - val_loss: 0.4563 - val_acc: 0.8377\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1710 - acc: 0.9409 - val_loss: 0.1162 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1066 - acc: 0.9589 - val_loss: 0.9482 - val_acc: 0.6192\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0809 - acc: 0.9714 - val_loss: 0.1176 - val_acc: 0.9559\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0714 - acc: 0.9744 - val_loss: 0.0834 - val_acc: 0.9739\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0656 - acc: 0.9760 - val_loss: 0.0845 - val_acc: 0.9739\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0575 - acc: 0.9805 - val_loss: 0.1067 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0465 - acc: 0.9830 - val_loss: 0.2234 - val_acc: 0.9379\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0342 - acc: 0.9875 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0418 - acc: 0.9840 - val_loss: 0.1614 - val_acc: 0.9539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da24e090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0307 - acc: 0.9870 - val_loss: 0.1558 - val_acc: 0.9579\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0264 - acc: 0.9880 - val_loss: 0.1269 - val_acc: 0.9679\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0318 - acc: 0.9890 - val_loss: 0.1332 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.2665 - val_acc: 0.9579\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0253 - acc: 0.9920 - val_loss: 0.1263 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ffa90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0079 - acc: 0.9985 - val_loss: 0.1139 - val_acc: 0.9719\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1135 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0075 - acc: 0.9970 - val_loss: 0.1429 - val_acc: 0.9719\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0064 - acc: 0.9975 - val_loss: 0.1326 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1435 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50d23c9bd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1295 - val_acc: 0.9699\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1321 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.1329 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1502 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ff790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
