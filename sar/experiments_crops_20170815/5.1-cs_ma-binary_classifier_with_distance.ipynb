{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "0.19.1\n",
      "2.0.0\n",
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, Add, merge, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print kv\n",
    "print sv\n",
    "print mv\n",
    "print nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'utils.pyc'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary turbine classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'\n",
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/validate/50x50/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_turbine():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/train/50x50/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/validate/50x50/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'other'\n",
    "    train_class_array = [0]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [1]\n",
    "    train_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_turbine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1996\n",
      "training features: 1996\n",
      "validation crops: 499\n",
      "validation features: 499\n",
      "<type 'list'> <type 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 50, 50, 1)\n",
      "(1996, 1)\n",
      "(1996, 1)\n",
      "(499, 50, 50, 1)\n",
      "(499, 1)\n",
      "(499, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 50, 50, 32)    320         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 12, 12, 64)    256         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 12, 12, 64)    256         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 12, 12, 64)    256         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 12, 12, 3)     0           conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 432)           0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 433)           0           flatten_7[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             434         merge_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.5071 - acc: 0.8793 - val_loss: 0.2723 - val_acc: 0.9399\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.2088 - acc: 0.9299 - val_loss: 0.2562 - val_acc: 0.9539\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1212 - acc: 0.9504 - val_loss: 0.1770 - val_acc: 0.9539\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1019 - acc: 0.9634 - val_loss: 0.1601 - val_acc: 0.9539\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0766 - acc: 0.9739 - val_loss: 0.1522 - val_acc: 0.9599\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0678 - acc: 0.9719 - val_loss: 0.1316 - val_acc: 0.9699\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0650 - acc: 0.9770 - val_loss: 0.1186 - val_acc: 0.9699\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0381 - acc: 0.9845 - val_loss: 0.1088 - val_acc: 0.9719\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0447 - acc: 0.9860 - val_loss: 0.1510 - val_acc: 0.9579\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0311 - acc: 0.9880 - val_loss: 0.3646 - val_acc: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c02a50>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0193 - acc: 0.9945 - val_loss: 0.0886 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0889 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9800\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 8.1095e-04 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 4.8696e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9820\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 3.2425e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 1.7841e-04 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 1.1328e-04 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe82089ae10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_distance_feature_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 50, 50, 32)    320         input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 12, 12, 64)    256         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 12, 12, 64)    256         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 12, 12, 64)    256         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 12, 12, 3)     0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 432)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 433)           0           flatten_8[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             434         merge_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.3219 - acc: 0.8808 - val_loss: 0.1907 - val_acc: 0.9459\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1721 - acc: 0.9314 - val_loss: 1.8712 - val_acc: 0.5050\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1591 - acc: 0.9464 - val_loss: 0.1064 - val_acc: 0.9619\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 22s - loss: 0.1119 - acc: 0.9589 - val_loss: 0.1018 - val_acc: 0.9719\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0998 - acc: 0.9614 - val_loss: 0.0856 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0789 - acc: 0.9689 - val_loss: 0.1000 - val_acc: 0.9659\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0723 - acc: 0.9729 - val_loss: 0.2282 - val_acc: 0.9399\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 36s - loss: 0.0512 - acc: 0.9795 - val_loss: 0.1038 - val_acc: 0.9659\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0472 - acc: 0.9825 - val_loss: 0.0940 - val_acc: 0.9739\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0488 - acc: 0.9820 - val_loss: 0.0977 - val_acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2fad0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0315 - acc: 0.9875 - val_loss: 0.0756 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0694 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0089 - acc: 0.9985 - val_loss: 0.0722 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0733 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 0.9820\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0038 - acc: 0.9995 - val_loss: 0.0838 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0852 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0897 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0914 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0908 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2f390>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_distance_feature_dropout_p_0p3_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary other classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'\n",
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/validate/50x50/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_other():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/train/50x50/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/validate/50x50/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_turbine'\n",
    "    train_class_array = [0]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'oil_and_turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [1]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'oil_and_turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'oil_and_turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_other()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1996\n",
      "training features: 1996\n",
      "validation crops: 499\n",
      "validation features: 499\n",
      "<type 'list'> <type 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 50, 50, 1)\n",
      "(1996, 1)\n",
      "(1996, 1)\n",
      "(499, 50, 50, 1)\n",
      "(499, 1)\n",
      "(499, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0\n",
    "\n",
    "Accuracy on validation stalls around 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 50, 50, 32)    320         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 12, 12, 64)    256         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 12, 12, 64)    256         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 12, 12, 64)    256         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 12, 12, 3)     0           conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 432)           0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 433)           0           flatten_9[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             434         merge_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.4324 - acc: 0.8377 - val_loss: 0.4751 - val_acc: 0.7735\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.2515 - acc: 0.9073 - val_loss: 0.1810 - val_acc: 0.9419\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1565 - acc: 0.9404 - val_loss: 0.1848 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1239 - acc: 0.9514 - val_loss: 0.1492 - val_acc: 0.9499\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1121 - acc: 0.9574 - val_loss: 0.1735 - val_acc: 0.9379\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0782 - acc: 0.9694 - val_loss: 0.4967 - val_acc: 0.8377\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0742 - acc: 0.9734 - val_loss: 0.1384 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0574 - acc: 0.9845 - val_loss: 0.2162 - val_acc: 0.9399\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 20s - loss: 0.0411 - acc: 0.9855 - val_loss: 0.1814 - val_acc: 0.9499\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0416 - acc: 0.9830 - val_loss: 0.1578 - val_acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7dc1fcfd0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0172 - acc: 0.9960 - val_loss: 0.1279 - val_acc: 0.9499\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0044 - acc: 0.9995 - val_loss: 0.1194 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9519\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1285 - val_acc: 0.9639\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 30s - loss: 6.0832e-04 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9619\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 34s - loss: 3.8086e-04 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9579\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 34s - loss: 2.0374e-04 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 34s - loss: 1.5033e-04 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9619\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 34s - loss: 1.1596e-04 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 33s - loss: 5.7145e-05 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2f810>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 50, 50, 32)    320         input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 12, 12, 64)    256         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 12, 12, 64)    256         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 12, 12, 64)    256         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 12, 12, 3)     0           conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 432)           0           dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 433)           0           flatten_10[0][0]                 \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             434         merge_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.4501 - acc: 0.8101 - val_loss: 0.3883 - val_acc: 0.8236\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.2956 - acc: 0.8848 - val_loss: 0.2846 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2269 - acc: 0.9083 - val_loss: 0.7400 - val_acc: 0.6453\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2051 - acc: 0.9228 - val_loss: 0.3110 - val_acc: 0.8537\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1731 - acc: 0.9394 - val_loss: 0.1576 - val_acc: 0.9399\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1475 - acc: 0.9444 - val_loss: 0.1333 - val_acc: 0.9359\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1222 - acc: 0.9529 - val_loss: 0.1140 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.1117 - acc: 0.9619 - val_loss: 0.1221 - val_acc: 0.9579\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1015 - acc: 0.9574 - val_loss: 0.1980 - val_acc: 0.9359\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0740 - acc: 0.9719 - val_loss: 0.2228 - val_acc: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d95967d0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0572 - acc: 0.9775 - val_loss: 0.1134 - val_acc: 0.9639\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0313 - acc: 0.9875 - val_loss: 0.1252 - val_acc: 0.9599\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.1138 - val_acc: 0.9659\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0166 - acc: 0.9955 - val_loss: 0.1218 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.1245 - val_acc: 0.9679\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0163 - acc: 0.9945 - val_loss: 0.1114 - val_acc: 0.9699\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.1134 - val_acc: 0.9719\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 30s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.1138 - val_acc: 0.9699\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0082 - acc: 0.9985 - val_loss: 0.1180 - val_acc: 0.9719\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0097 - acc: 0.9975 - val_loss: 0.1282 - val_acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d9596f50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.1299 - val_acc: 0.9699\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.1321 - val_acc: 0.9639\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9719\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.1232 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0045 - acc: 0.9995 - val_loss: 0.1264 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 0.9995 - val_loss: 0.1344 - val_acc: 0.9619\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0040 - acc: 0.9995 - val_loss: 0.1201 - val_acc: 0.9699\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1208 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1281 - val_acc: 0.9659\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe82060b190>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/other_binary_distance_feature_dropout_p_0p3_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary oil and gas classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'\n",
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/train/50x50'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_oil():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/train/50x50/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/validate/50x50/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_gas_infrastructure'\n",
    "    train_class_array = [1]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'oil_and_gas_infrastructure'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_oil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1996\n",
      "training features: 1996\n",
      "validation crops: 499\n",
      "validation features: 499\n",
      "<type 'list'> <type 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 50, 50, 1)\n",
      "(1996, 1)\n",
      "(1996, 1)\n",
      "(499, 50, 50, 1)\n",
      "(499, 1)\n",
      "(499, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 50, 50, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 12, 12, 3)     1731        batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 12, 12, 3)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 433)           0           flatten_1[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             434         merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.7732 - acc: 0.8126 - val_loss: 0.4563 - val_acc: 0.8377\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1710 - acc: 0.9409 - val_loss: 0.1162 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1066 - acc: 0.9589 - val_loss: 0.9482 - val_acc: 0.6192\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0809 - acc: 0.9714 - val_loss: 0.1176 - val_acc: 0.9559\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0714 - acc: 0.9744 - val_loss: 0.0834 - val_acc: 0.9739\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0656 - acc: 0.9760 - val_loss: 0.0845 - val_acc: 0.9739\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0575 - acc: 0.9805 - val_loss: 0.1067 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0465 - acc: 0.9830 - val_loss: 0.2234 - val_acc: 0.9379\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0342 - acc: 0.9875 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0418 - acc: 0.9840 - val_loss: 0.1614 - val_acc: 0.9539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da24e090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0307 - acc: 0.9870 - val_loss: 0.1558 - val_acc: 0.9579\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0264 - acc: 0.9880 - val_loss: 0.1269 - val_acc: 0.9679\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0318 - acc: 0.9890 - val_loss: 0.1332 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.2665 - val_acc: 0.9579\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0253 - acc: 0.9920 - val_loss: 0.1263 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ffa90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0079 - acc: 0.9985 - val_loss: 0.1139 - val_acc: 0.9719\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1135 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0075 - acc: 0.9970 - val_loss: 0.1429 - val_acc: 0.9719\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0064 - acc: 0.9975 - val_loss: 0.1326 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1435 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50d23c9bd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1295 - val_acc: 0.9699\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1321 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.1329 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1502 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ff790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/oil_binary_distance_feature_dropout_p_0p3_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
