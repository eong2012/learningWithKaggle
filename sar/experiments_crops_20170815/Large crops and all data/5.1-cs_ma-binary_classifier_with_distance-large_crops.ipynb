{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "0.19.1\n",
      "2.0.0\n",
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, Add, merge, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print kv\n",
    "print sv\n",
    "print mv\n",
    "print nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'utils.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Binary turbine classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier_large_crops/'\n",
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/train/240x240/'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/validate/240x240/'\n",
    "\n",
    "# trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier_large_crops/'\n",
    "# train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/train/240x240'\n",
    "# valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/validate/240x240/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_turbine():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/train/240x240/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/validate/240x240/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_gas_infrastructure'\n",
    "    train_class_array = [0]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [1]\n",
    "    train_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'oil_and_gas_infrastructure'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_turbine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1973\n",
      "training features: 1973\n",
      "validation crops: 498\n",
      "validation features: 498\n",
      "<type 'list'> <type 'numpy.ndarray'> (240, 240)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1973, 240, 240, 1)\n",
      "(1973, 1)\n",
      "(1973, 1)\n",
      "(498, 240, 240, 1)\n",
      "(498, 1)\n",
      "(498, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 240, 240, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 240, 240, 32)  320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 120, 120, 32)  0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 120, 120, 64)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 60, 60, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 60, 60, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 60, 60, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 60, 60, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 60, 60, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 60, 60, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 60, 60, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 60, 60, 3)     1731        batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 60, 60, 3)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 10800)         0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 10801)         0           flatten_1[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             10802       merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 142,901\n",
      "Trainable params: 142,517\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1973 samples, validate on 498 samples\n",
      "Epoch 1/10\n",
      "1973/1973 [==============================] - 414s - loss: 0.4546 - acc: 0.9184 - val_loss: 0.2256 - val_acc: 0.9337\n",
      "Epoch 2/10\n",
      "1973/1973 [==============================] - 411s - loss: 0.1548 - acc: 0.9635 - val_loss: 0.4674 - val_acc: 0.9438\n",
      "Epoch 3/10\n",
      "1973/1973 [==============================] - 411s - loss: 0.1080 - acc: 0.9777 - val_loss: 0.2799 - val_acc: 0.9598\n",
      "Epoch 4/10\n",
      "1973/1973 [==============================] - 411s - loss: 0.0924 - acc: 0.9812 - val_loss: 0.3986 - val_acc: 0.9538\n",
      "Epoch 5/10\n",
      "1792/1973 [==========================>...] - ETA: 34s - loss: 0.0586 - acc: 0.9877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-15b4efe325c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=([np_valid_crops, np_valid_feature], np_valid_class))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0193 - acc: 0.9945 - val_loss: 0.0886 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0889 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9800\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 8.1095e-04 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 4.8696e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9820\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 3.2425e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 1.7841e-04 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 1.1328e-04 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe82089ae10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_distance_feature_model_large_crop.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 50, 50, 32)    320         input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 12, 12, 64)    256         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 12, 12, 64)    256         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 12, 12, 64)    256         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 12, 12, 3)     0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 432)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 433)           0           flatten_8[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             434         merge_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.3219 - acc: 0.8808 - val_loss: 0.1907 - val_acc: 0.9459\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1721 - acc: 0.9314 - val_loss: 1.8712 - val_acc: 0.5050\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1591 - acc: 0.9464 - val_loss: 0.1064 - val_acc: 0.9619\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 22s - loss: 0.1119 - acc: 0.9589 - val_loss: 0.1018 - val_acc: 0.9719\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0998 - acc: 0.9614 - val_loss: 0.0856 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0789 - acc: 0.9689 - val_loss: 0.1000 - val_acc: 0.9659\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0723 - acc: 0.9729 - val_loss: 0.2282 - val_acc: 0.9399\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 36s - loss: 0.0512 - acc: 0.9795 - val_loss: 0.1038 - val_acc: 0.9659\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0472 - acc: 0.9825 - val_loss: 0.0940 - val_acc: 0.9739\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0488 - acc: 0.9820 - val_loss: 0.0977 - val_acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2fad0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0315 - acc: 0.9875 - val_loss: 0.0756 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0694 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0089 - acc: 0.9985 - val_loss: 0.0722 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0733 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 0.9820\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.0038 - acc: 0.9995 - val_loss: 0.0838 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0852 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0897 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0914 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0908 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2f390>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/turbine_binary_distance_feature_dropout_p_0p3_model_large_crops.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary other classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'\n",
    "# train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/train/50x50'\n",
    "# valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/validate/50x50/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_other():\n",
    "    \n",
    "#     train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/train/50x50/'\n",
    "#     valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/other_classifier/validate/50x50/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_gas_infrastructure'\n",
    "    train_class_array = [0]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [1]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'oil_and_gas_infrastructure'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_other()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1996\n",
      "training features: 1996\n",
      "validation crops: 499\n",
      "validation features: 499\n",
      "<type 'list'> <type 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 50, 50, 1)\n",
      "(1996, 1)\n",
      "(1996, 1)\n",
      "(499, 50, 50, 1)\n",
      "(499, 1)\n",
      "(499, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0\n",
    "\n",
    "Accuracy on validation stalls around 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 50, 50, 32)    320         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 12, 12, 64)    256         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 12, 12, 64)    256         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 12, 12, 64)    256         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 12, 12, 3)     0           conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 432)           0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 433)           0           flatten_9[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             434         merge_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.4324 - acc: 0.8377 - val_loss: 0.4751 - val_acc: 0.7735\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 34s - loss: 0.2515 - acc: 0.9073 - val_loss: 0.1810 - val_acc: 0.9419\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1565 - acc: 0.9404 - val_loss: 0.1848 - val_acc: 0.9238\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1239 - acc: 0.9514 - val_loss: 0.1492 - val_acc: 0.9499\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.1121 - acc: 0.9574 - val_loss: 0.1735 - val_acc: 0.9379\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0782 - acc: 0.9694 - val_loss: 0.4967 - val_acc: 0.8377\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0742 - acc: 0.9734 - val_loss: 0.1384 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 35s - loss: 0.0574 - acc: 0.9845 - val_loss: 0.2162 - val_acc: 0.9399\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 20s - loss: 0.0411 - acc: 0.9855 - val_loss: 0.1814 - val_acc: 0.9499\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0416 - acc: 0.9830 - val_loss: 0.1578 - val_acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7dc1fcfd0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0172 - acc: 0.9960 - val_loss: 0.1279 - val_acc: 0.9499\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0044 - acc: 0.9995 - val_loss: 0.1194 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9519\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 19s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1285 - val_acc: 0.9639\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 30s - loss: 6.0832e-04 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9619\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 34s - loss: 3.8086e-04 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9579\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 34s - loss: 2.0374e-04 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 34s - loss: 1.5033e-04 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.9619\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 34s - loss: 1.1596e-04 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 33s - loss: 5.7145e-05 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f6c2f810>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 50, 50, 32)    320         input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D)  (None, 25, 25, 32)    0           conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 25, 25, 64)    18496       max_pooling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 12, 12, 64)    36928       max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 12, 12, 64)    256         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 12, 12, 64)    256         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 12, 12, 64)    256         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 12, 12, 3)     1731        batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 12, 12, 3)     0           conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 432)           0           dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 433)           0           flatten_10[0][0]                 \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             434         merge_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.4501 - acc: 0.8101 - val_loss: 0.3883 - val_acc: 0.8236\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.2956 - acc: 0.8848 - val_loss: 0.2846 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2269 - acc: 0.9083 - val_loss: 0.7400 - val_acc: 0.6453\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.2051 - acc: 0.9228 - val_loss: 0.3110 - val_acc: 0.8537\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1731 - acc: 0.9394 - val_loss: 0.1576 - val_acc: 0.9399\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1475 - acc: 0.9444 - val_loss: 0.1333 - val_acc: 0.9359\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1222 - acc: 0.9529 - val_loss: 0.1140 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.1117 - acc: 0.9619 - val_loss: 0.1221 - val_acc: 0.9579\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.1015 - acc: 0.9574 - val_loss: 0.1980 - val_acc: 0.9359\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0740 - acc: 0.9719 - val_loss: 0.2228 - val_acc: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d95967d0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0572 - acc: 0.9775 - val_loss: 0.1134 - val_acc: 0.9639\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0313 - acc: 0.9875 - val_loss: 0.1252 - val_acc: 0.9599\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0282 - acc: 0.9900 - val_loss: 0.1138 - val_acc: 0.9659\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0166 - acc: 0.9955 - val_loss: 0.1218 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 33s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.1245 - val_acc: 0.9679\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0163 - acc: 0.9945 - val_loss: 0.1114 - val_acc: 0.9699\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 32s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.1134 - val_acc: 0.9719\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 30s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.1138 - val_acc: 0.9699\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0082 - acc: 0.9985 - val_loss: 0.1180 - val_acc: 0.9719\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0097 - acc: 0.9975 - val_loss: 0.1282 - val_acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7d9596f50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.1299 - val_acc: 0.9699\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.1321 - val_acc: 0.9639\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9719\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.1232 - val_acc: 0.9679\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0045 - acc: 0.9995 - val_loss: 0.1264 - val_acc: 0.9699\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0043 - acc: 0.9995 - val_loss: 0.1344 - val_acc: 0.9619\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0040 - acc: 0.9995 - val_loss: 0.1201 - val_acc: 0.9699\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1208 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1281 - val_acc: 0.9659\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe82060b190>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/turbine_classifier/other_binary_distance_feature_dropout_p_0p3_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary oil and gas classifier, with distance-to-land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier/'\n",
    "# train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/train/50x50'\n",
    "# valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_oil():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/train/50x50/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/validate/50x50/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_gas_infrastructure'\n",
    "    train_class_array = [1]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'oil_and_gas_infrastructure'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.iteritems():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_oil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1996\n",
      "training features: 1996\n",
      "validation crops: 499\n",
      "validation features: 499\n",
      "<type 'list'> <type 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print \"training crops:\", len(train_crops)\n",
    "print \"training features:\", len(train_feature)\n",
    "print \"validation crops:\", len(valid_crops)\n",
    "print \"validation features:\", len(valid_feature)\n",
    "print type(train_crops), type(train_crops[0]), train_crops[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 50, 50, 1)\n",
      "(1996, 1)\n",
      "(1996, 1)\n",
      "(499, 50, 50, 1)\n",
      "(499, 1)\n",
      "(499, 1)\n"
     ]
    }
   ],
   "source": [
    "print np_train_crops.shape\n",
    "print np_train_feature.shape\n",
    "print np_train_class.shape\n",
    "\n",
    "print np_valid_crops.shape\n",
    "print np_valid_feature.shape\n",
    "print np_valid_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 50, 50, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 12, 12, 3)     1731        batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 12, 12, 3)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 433)           0           flatten_1[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             434         merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0.3\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.7732 - acc: 0.8126 - val_loss: 0.4563 - val_acc: 0.8377\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1710 - acc: 0.9409 - val_loss: 0.1162 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.1066 - acc: 0.9589 - val_loss: 0.9482 - val_acc: 0.6192\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0809 - acc: 0.9714 - val_loss: 0.1176 - val_acc: 0.9559\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0714 - acc: 0.9744 - val_loss: 0.0834 - val_acc: 0.9739\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0656 - acc: 0.9760 - val_loss: 0.0845 - val_acc: 0.9739\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0575 - acc: 0.9805 - val_loss: 0.1067 - val_acc: 0.9599\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0465 - acc: 0.9830 - val_loss: 0.2234 - val_acc: 0.9379\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0342 - acc: 0.9875 - val_loss: 0.1138 - val_acc: 0.9679\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 18s - loss: 0.0418 - acc: 0.9840 - val_loss: 0.1614 - val_acc: 0.9539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da24e090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0307 - acc: 0.9870 - val_loss: 0.1558 - val_acc: 0.9579\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0264 - acc: 0.9880 - val_loss: 0.1269 - val_acc: 0.9679\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0318 - acc: 0.9890 - val_loss: 0.1332 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0203 - acc: 0.9950 - val_loss: 0.2665 - val_acc: 0.9579\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0253 - acc: 0.9920 - val_loss: 0.1263 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ffa90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0079 - acc: 0.9985 - val_loss: 0.1139 - val_acc: 0.9719\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1135 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0075 - acc: 0.9970 - val_loss: 0.1429 - val_acc: 0.9719\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0064 - acc: 0.9975 - val_loss: 0.1326 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1435 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50d23c9bd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1996 samples, validate on 499 samples\n",
      "Epoch 1/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1295 - val_acc: 0.9699\n",
      "Epoch 2/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9719\n",
      "Epoch 3/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1321 - val_acc: 0.9699\n",
      "Epoch 4/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.1329 - val_acc: 0.9699\n",
      "Epoch 5/5\n",
      "1996/1996 [==============================] - 18s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1502 - val_acc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50da2ff790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ubuntu/data/sar/experiment_crops_20170815/binary_experiments/oil_and_gas_infrastructure_classifier/oil_binary_distance_feature_dropout_p_0p3_model_large_crop.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
