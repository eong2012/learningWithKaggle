{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n",
      "0.19.0\n",
      "2.0.0\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, Add, merge, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print(kv)\n",
    "print(sv) \n",
    "print(mv) \n",
    "print(nv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12541888480520012064\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6736440175798923139\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n",
      "0.19.0\n",
      "2.0.0\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "# from keras.layers# import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, Add, merge, concatenate\n",
    "# from keras.models import Model\n",
    "# from keras.utils.layer_utils import print_summary\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import backend as K\n",
    "# from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print(kv)\n",
    "print(sv) \n",
    "print(mv) \n",
    "print(nv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9871679898468772912\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6021598521292376988\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local files\n",
    "import utils_python3\n",
    "#reload(utils_python3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/trained_models/5.0-as-binary_classifier_large_crops/'\n",
    "train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/train/240x240/'\n",
    "valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/validate/240x240/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dist2land_experiment_crops_20170815_turbine():\n",
    "    \n",
    "    train_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/train/240x240/'\n",
    "    valid_dir = '/home/ubuntu/data/sar/experiment_crops_20170815/validate/240x240/'\n",
    "\n",
    "    train_class = []           \n",
    "    train_filename = []\n",
    "    train_crops = []\n",
    "    train_feature = []\n",
    "\n",
    "    valid_class = []\n",
    "    valid_filename = []\n",
    "    valid_crops = []\n",
    "    valid_feature = []\n",
    "\n",
    "    train_class_desc = 'oil_and_gas_infrastructure'\n",
    "    train_class_array = [0]\n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [1]\n",
    "    train_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_turbine.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    train_class_array = [0]\n",
    "    train_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/train/distance_to_land/experiments_train_other.json') as json_data:\n",
    "        json_train_data = json.load(json_data)\n",
    "        for id_, item in json_train_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            train_filename.append(fn)\n",
    "            train_feature.append(item['distance to land'])\n",
    "            train_class.append(train_class_array)\n",
    "            file_path = train_dir + '/' + train_class_desc + '/' + fn\n",
    "            try:\n",
    "                img  = imread(file_path)\n",
    "            except IOError:\n",
    "                continue\n",
    "            train_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'oil_and_gas_infrastructure'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_oil_and_gas_infrastructure.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [1]\n",
    "    valid_class_desc = 'turbine'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_turbine.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    "\n",
    "    valid_class_array = [0]\n",
    "    valid_class_desc = 'other'  \n",
    "    with open('/home/ubuntu/data/sar/experiment_crops_20170815/validate/distance_to_land/experiments_validate_other.json') as json_data:\n",
    "        json_validation_data = json.load(json_data)\n",
    "        for id_, item in json_validation_data.items():\n",
    "            fn = id_.replace('.tif', '.png')\n",
    "            valid_filename.append(fn)\n",
    "            valid_feature.append(item['distance to land'])\n",
    "            valid_class.append(valid_class_array)\n",
    "            file_path = valid_dir + '/' + valid_class_desc + '/' + fn\n",
    "            img  = imread(file_path)\n",
    "            valid_crops.append(img)\n",
    " \n",
    "    return train_crops, train_filename, train_feature, train_class, valid_crops, valid_filename, valid_feature, valid_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = add_dist2land_experiment_crops_20170815_turbine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 1973\n",
      "training features: 1973\n",
      "validation crops: 498\n",
      "validation features: 498\n",
      "<class 'list'> <class 'numpy.ndarray'> (240, 240)\n"
     ]
    }
   ],
   "source": [
    "print(\"training crops:\", len(train_crops))\n",
    "print(\"training features:\", len(train_feature))\n",
    "print(\"validation crops:\", len(valid_crops))\n",
    "print(\"validation features:\", len(valid_feature))\n",
    "print(type(train_crops), type(train_crops[0]), train_crops[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1973, 240, 240, 1)\n",
      "(1973, 1)\n",
      "(1973, 1)\n",
      "(498, 240, 240, 1)\n",
      "(498, 1)\n",
      "(498, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np_train_crops.shape)\n",
    "print(np_train_feature.shape)\n",
    "print(np_train_class.shape)\n",
    "print(np_valid_crops.shape)\n",
    "print(np_valid_feature.shape)\n",
    "print(np_valid_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 240, 240, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 240, 240, 32)  320         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 120, 120, 32)  0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 120, 120, 64)  18496       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 60, 60, 64)    0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 60, 60, 64)    36928       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 60, 60, 64)    256         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 60, 60, 64)    36928       batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 60, 60, 64)    256         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 60, 60, 64)    36928       batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 60, 60, 64)    256         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 60, 60, 3)     1731        batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 60, 60, 3)     0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 10800)         0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 10801)         0           flatten_2[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             10802       merge_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 142,901\n",
      "Trainable params: 142,517\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python3.4/dist-packages/keras/legacy/layers.py:458: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1973 samples, validate on 498 samples\n",
      "Epoch 1/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.2630 - acc: 0.9184 - val_loss: 0.4347 - val_acc: 0.8755\n",
      "Epoch 2/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0801 - acc: 0.9701 - val_loss: 0.1643 - val_acc: 0.9659\n",
      "Epoch 3/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0440 - acc: 0.9873 - val_loss: 0.2385 - val_acc: 0.9458\n",
      "Epoch 4/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0358 - acc: 0.9868 - val_loss: 0.2692 - val_acc: 0.9518\n",
      "Epoch 5/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0247 - acc: 0.9919 - val_loss: 0.2540 - val_acc: 0.9558\n",
      "Epoch 6/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0188 - acc: 0.9949 - val_loss: 0.4417 - val_acc: 0.9277\n",
      "Epoch 7/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0275 - acc: 0.9909 - val_loss: 0.3180 - val_acc: 0.9578\n",
      "Epoch 8/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.4191 - val_acc: 0.9398\n",
      "Epoch 9/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0047 - acc: 0.9990 - val_loss: 0.2706 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0075 - acc: 0.9985 - val_loss: 0.3681 - val_acc: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5298f86048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.3\n",
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1973 samples, validate on 498 samples\n",
      "Epoch 1/10\n",
      "1973/1973 [==============================] - 16s - loss: 0.0027 - acc: 0.9985 - val_loss: 0.3087 - val_acc: 0.9578\n",
      "Epoch 2/10\n",
      "1973/1973 [==============================] - 16s - loss: 2.4234e-04 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.9598\n",
      "Epoch 3/10\n",
      "1973/1973 [==============================] - 16s - loss: 9.0284e-05 - acc: 1.0000 - val_loss: 0.3207 - val_acc: 0.9639\n",
      "Epoch 4/10\n",
      "1973/1973 [==============================] - 16s - loss: 1.8294e-05 - acc: 1.0000 - val_loss: 0.2957 - val_acc: 0.9618\n",
      "Epoch 5/10\n",
      "1973/1973 [==============================] - 16s - loss: 4.6277e-06 - acc: 1.0000 - val_loss: 0.3241 - val_acc: 0.9659\n",
      "Epoch 6/10\n",
      "1973/1973 [==============================] - 16s - loss: 1.7115e-06 - acc: 1.0000 - val_loss: 0.3250 - val_acc: 0.9659\n",
      "Epoch 7/10\n",
      "1973/1973 [==============================] - 16s - loss: 1.5015e-06 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.9639\n",
      "Epoch 8/10\n",
      "1973/1973 [==============================] - 16s - loss: 2.2667e-07 - acc: 1.0000 - val_loss: 0.3156 - val_acc: 0.9639\n",
      "Epoch 9/10\n",
      "1973/1973 [==============================] - 16s - loss: 1.8846e-07 - acc: 1.0000 - val_loss: 0.3333 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "1973/1973 [==============================] - 16s - loss: 1.3229e-07 - acc: 1.0000 - val_loss: 0.3202 - val_acc: 0.9639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52983f1dd8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
