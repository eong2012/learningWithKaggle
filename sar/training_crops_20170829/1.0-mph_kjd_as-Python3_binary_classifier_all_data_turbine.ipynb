{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n",
      "0.19.0\n",
      "2.0.0\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, Add, merge, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print(kv)\n",
    "print(sv) \n",
    "print(mv) \n",
    "print(nv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils_python3\n",
    "#reload(utils_python3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/training_crops_20170829/trained_models/1.0-mph_kjd_as-Python3_binary_classifier_all_data/'\n",
    "train_dir = '/home/ubuntu/data/sar/training_crops_20170829/train/50x50/'\n",
    "valid_dir = '/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training_crops json into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756\n",
      "501\n",
      "2234\n",
      "501\n",
      "6198\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "utils_python3.split_all_json_into_train_validate('oil_and_gas_infrastructure')\n",
    "utils_python3.split_all_json_into_train_validate('other')\n",
    "utils_python3.split_all_json_into_train_validate('turbine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert tif2png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN FROM ME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/oil_and_gas_infrastructure/ 1756\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/oil_and_gas_infrastructure/ 1756 3512\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/other/ 2234\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/other/ 2234 4468\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/turbine/ 6198\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/turbine/ 6198 12396\n"
     ]
    }
   ],
   "source": [
    "utils_python3.tif2png(src_dir=train_dir+\"oil_and_gas_infrastructure/\", dest_dir=train_dir+\"oil_and_gas_infrastructure/\")\n",
    "utils_python3.tif2png(src_dir=train_dir+\"other/\", dest_dir=train_dir+\"other/\")\n",
    "utils_python3.tif2png(src_dir=train_dir+\"turbine/\", dest_dir=train_dir+\"turbine/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/oil_and_gas_infrastructure/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/oil_and_gas_infrastructure/ 501 1002\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/other/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/other/ 501 1002\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/turbine/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/turbine/ 501 1002\n"
     ]
    }
   ],
   "source": [
    "utils_python3.tif2png(src_dir=valid_dir+\"oil_and_gas_infrastructure/\", dest_dir=valid_dir+\"oil_and_gas_infrastructure/\")\n",
    "utils_python3.tif2png(src_dir=valid_dir+\"other/\", dest_dir=valid_dir+\"other/\")\n",
    "utils_python3.tif2png(src_dir=valid_dir+\"turbine/\", dest_dir=valid_dir+\"turbine/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dist2land feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = utils_python3.add_dist2land_training_crops_20170829_binary_turbine(\"50x50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 10188\n",
      "training features: 10188\n",
      "validation crops: 1503\n",
      "validation features: 1503\n",
      "<class 'list'> <class 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"training crops:\", len(train_crops))\n",
    "print(\"training features:\", len(train_feature))\n",
    "print(\"validation crops:\", len(valid_crops))\n",
    "print(\"validation features:\", len(valid_feature))\n",
    "print(type(train_crops), type(train_crops[0]), train_crops[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10188, 50, 50, 1)\n",
      "(10188, 1)\n",
      "(10188, 1)\n",
      "(1503, 50, 50, 1)\n",
      "(1503, 1)\n",
      "(1503, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np_train_crops.shape)\n",
    "print(np_train_feature.shape)\n",
    "print(np_train_class.shape)\n",
    "print(np_valid_crops.shape)\n",
    "print(np_valid_feature.shape)\n",
    "print(np_valid_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 50, 50, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 12, 12, 3)     1731        batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 12, 12, 3)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 432)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dist2land_input (InputLayer)     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 433)           0           flatten_1[0][0]                  \n",
      "                                                                   dist2land_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             434         merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 132,533\n",
      "Trainable params: 132,149\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "/usr/local/lib/python3.4/dist-packages/keras/legacy/layers.py:458: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,), name='dist2land_input')\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = merge([x, dist2land_input], 'concat')\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(outputs=x, inputs=[classifier_input, dist2land_input])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 8s - loss: 0.1866 - acc: 0.9344 - val_loss: 0.1570 - val_acc: 0.9448\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0830 - acc: 0.9712 - val_loss: 0.0549 - val_acc: 0.9787\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0616 - acc: 0.9760 - val_loss: 0.0665 - val_acc: 0.9741\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0463 - acc: 0.9828 - val_loss: 0.0829 - val_acc: 0.9681\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0421 - acc: 0.9845 - val_loss: 0.0769 - val_acc: 0.9701\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0339 - acc: 0.9867 - val_loss: 0.0567 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0251 - acc: 0.9908 - val_loss: 0.0621 - val_acc: 0.9794\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0520 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0174 - acc: 0.9931 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0173 - acc: 0.9938 - val_loss: 0.0351 - val_acc: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee46c30f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.3\n",
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 5.7092e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9880\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.9523e-04 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9874\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 8.7015e-05 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9894\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 3.4332e-05 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.5008e-05 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9887\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 7.7544e-06 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 4.0071e-06 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 0.9867\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.6275e-06 - acc: 1.0000 - val_loss: 0.0601 - val_acc: 0.9880\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.0205e-06 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee4710390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
