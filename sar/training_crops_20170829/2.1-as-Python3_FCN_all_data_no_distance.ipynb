{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n",
      "0.19.0\n",
      "2.0.0\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, merge, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Add, Multiply, Average, Maximum, Concatenate, Dot\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print(kv)\n",
    "print(sv) \n",
    "print(mv) \n",
    "print(nv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils_python3\n",
    "#reload(utils_python3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/training_crops_20170829/trained_models/2.0-as-Python3_FCN_all_data/'\n",
    "train_dir = '/home/ubuntu/data/sar/training_crops_20170829/train/50x50/'\n",
    "valid_dir = '/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training_crops json into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in 1.0-mph_kjd_as-Python3_binary_classifier_all_data_turbine.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756\n",
      "501\n",
      "2234\n",
      "501\n",
      "6198\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "# utils_python3.split_all_json_into_train_validate('oil_and_gas_infrastructure')\n",
    "# utils_python3.split_all_json_into_train_validate('other')\n",
    "# utils_python3.split_all_json_into_train_validate('turbine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert tif2png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in 1.0-mph_kjd_as-Python3_binary_classifier_all_data_turbine.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/oil_and_gas_infrastructure/ 1756\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/oil_and_gas_infrastructure/ 1756 3512\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/other/ 2234\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/other/ 2234 4468\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/turbine/ 6198\n",
      "/home/ubuntu/data/sar/training_crops_20170829/train/50x50/turbine/ 6198 12396\n"
     ]
    }
   ],
   "source": [
    "# utils_python3.tif2png(src_dir=train_dir+\"oil_and_gas_infrastructure/\", dest_dir=train_dir+\"oil_and_gas_infrastructure/\")\n",
    "# utils_python3.tif2png(src_dir=train_dir+\"other/\", dest_dir=train_dir+\"other/\")\n",
    "# utils_python3.tif2png(src_dir=train_dir+\"turbine/\", dest_dir=train_dir+\"turbine/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/oil_and_gas_infrastructure/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/oil_and_gas_infrastructure/ 501 1002\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/other/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/other/ 501 1002\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/turbine/ 501\n",
      "/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/turbine/ 501 1002\n"
     ]
    }
   ],
   "source": [
    "# utils_python3.tif2png(src_dir=valid_dir+\"oil_and_gas_infrastructure/\", dest_dir=valid_dir+\"oil_and_gas_infrastructure/\")\n",
    "# utils_python3.tif2png(src_dir=valid_dir+\"other/\", dest_dir=valid_dir+\"other/\")\n",
    "# utils_python3.tif2png(src_dir=valid_dir+\"turbine/\", dest_dir=valid_dir+\"turbine/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10188 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()#rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator()#rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(50, 50),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical', \n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid_dir, \n",
    "        target_size=(50, 50),\n",
    "        shuffle=False,\n",
    "        batch_size=4,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# # Following based on https://github.com/asmith26/courses/blob/master/deeplearning1/nbs/lesson7.ipynb\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "m = Add()([dist2land_input, x])\n",
    "out = Activation('softmax')(m)\n",
    "\n",
    "\n",
    "model_with_distance = Model(inputs=[classifier_input, dist2land_input], outputs=out)\n",
    "model_with_distance.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 50, 50, 32)    320         input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 12, 12, 64)    256         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 12, 12, 64)    36928       batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 12, 12, 64)    256         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 6, 6, 64)      0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 6, 6, 64)      36928       max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 6, 6, 64)      256         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 3, 3, 64)      0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 3, 3, 3)       1731        max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 3, 3, 3)       0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 3)             0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 3)             0           input_4[0][0]                    \n",
      "                                                                   global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 3)             0           add_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 132,099\n",
      "Trainable params: 131,715\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_distance.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d96cfa7aad6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_with_distance).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 8s - loss: 0.1866 - acc: 0.9344 - val_loss: 0.1570 - val_acc: 0.9448\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0830 - acc: 0.9712 - val_loss: 0.0549 - val_acc: 0.9787\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0616 - acc: 0.9760 - val_loss: 0.0665 - val_acc: 0.9741\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0463 - acc: 0.9828 - val_loss: 0.0829 - val_acc: 0.9681\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0421 - acc: 0.9845 - val_loss: 0.0769 - val_acc: 0.9701\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0339 - acc: 0.9867 - val_loss: 0.0567 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0251 - acc: 0.9908 - val_loss: 0.0621 - val_acc: 0.9794\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0520 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0174 - acc: 0.9931 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0173 - acc: 0.9938 - val_loss: 0.0351 - val_acc: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee46c30f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.3\n",
    "lr = 0.001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 5.7092e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9880\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.9523e-04 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9874\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 8.7015e-05 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9894\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 3.4332e-05 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.5008e-05 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9887\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 7.7544e-06 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 4.0071e-06 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 0.9867\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.6275e-06 - acc: 1.0000 - val_loss: 0.0601 - val_acc: 0.9880\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 1.0205e-06 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ee4710390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
