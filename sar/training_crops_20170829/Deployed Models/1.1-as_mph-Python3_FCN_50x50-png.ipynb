{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n",
      "0.19.0\n",
      "2.0.0\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, Cropping2D\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation, merge, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Add, Multiply, Average, Maximum, Concatenate, Dot\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from scipy.misc import imread\n",
    "\n",
    "from keras import __version__ as kv\n",
    "from scipy import __version__ as sv\n",
    "from matplotlib import __version__ as mv\n",
    "from numpy import __version__ as nv\n",
    "\n",
    "print(kv)\n",
    "print(sv) \n",
    "print(mv) \n",
    "print(nv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Local files\n",
    "import utils_python3\n",
    "#reload(utils_python3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model_dir = '/home/ubuntu/data/sar/training_crops_20170829/trained_models/deployed_models/'\n",
    "train_dir = '/home/ubuntu/data/sar/training_crops_20170829/train/50x50/'\n",
    "valid_dir = '/home/ubuntu/data/sar/training_crops_20170829/validate/50x50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 50, 1)\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training_crops json into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in 1.0-mph_kjd_as-Python3_binary_classifier_all_data_turbine.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dist2land feature and tif images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crops, train_filename, train_feature, train_class, \\\n",
    "valid_crops, valid_filename, valid_feature, valid_class = utils_python3.add_dist2land_training_crops_20170829_multiclass(\"50x50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training crops: 10188\n",
      "training features: 10188\n",
      "validation crops: 1503\n",
      "validation features: 1503\n",
      "<class 'list'> <class 'numpy.ndarray'> (50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"training crops:\", len(train_crops))\n",
    "print(\"training features:\", len(train_feature))\n",
    "print(\"validation crops:\", len(valid_crops))\n",
    "print(\"validation features:\", len(valid_feature))\n",
    "print(type(train_crops), type(train_crops[0]), train_crops[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2, ...,  2,  4,  5],\n",
       "       [ 4,  4,  5, ...,  3,  3,  4],\n",
       "       [10, 12, 13, ...,  2,  2,  2],\n",
       "       ..., \n",
       "       [ 2,  3,  3, ...,  1,  1,  1],\n",
       "       [ 3,  3,  2, ...,  3,  3,  4],\n",
       "       [ 2,  3,  5, ...,  5,  5,  6]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_crops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_GRDH_1SDV_20170526T174153_20170526T174206_016756_01BD64_55E0_terrain_correction_29.png [1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqPiEFAgVn5AC+X/ij0GuVUpboAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca51a284a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_filename[0], train_class[0])\n",
    "plt.imshow( train_crops[0], cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_GRDH_1SDV_20170403T062215_20170403T062240_015976_01A590_B685_terrain_correction_290.png [0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca518a3048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_filename[3000], train_class[3000])\n",
    "plt.imshow( train_crops[3000], cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_GRDH_1SDV_20170607T174104_20170607T174129_016931_01C2D4_E8F6_subset1_6.png [0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDJHiC5EhUnwhMuT/AZZt4m8N3MvWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca5190d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_filename[10000], train_class[10000])\n",
    "plt.imshow( train_crops[10000], cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape for keras format\n",
    "np_train_class = np.array(train_class)\n",
    "np_train_filename = np.array(train_filename)\n",
    "np_train_crops = np.array(train_crops)\n",
    "np_train_feature = np.array(train_feature)\n",
    "\n",
    "np_valid_class = np.array(valid_class)\n",
    "np_valid_filename = np.array(valid_filename)\n",
    "np_valid_crops = np.array(valid_crops)\n",
    "np_valid_feature = np.array(valid_feature)\n",
    "\n",
    "np_train_crops = np.expand_dims(np_train_crops, axis=3)\n",
    "np_train_feature = np.expand_dims(np_train_feature, axis=1)\n",
    "\n",
    "np_valid_crops = np.expand_dims(np_valid_crops, axis=3)\n",
    "np_valid_feature = np.expand_dims(np_valid_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10188, 50, 50, 1)\n",
      "(10188, 1)\n",
      "(10188, 3)\n",
      "(1503, 50, 50, 1)\n",
      "(1503, 1)\n",
      "(1503, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np_train_crops.shape)\n",
    "print(np_train_feature.shape)\n",
    "print(np_train_class.shape)\n",
    "print(np_valid_crops.shape)\n",
    "print(np_valid_feature.shape)\n",
    "print(np_valid_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# # Following based on https://github.com/asmith26/courses/blob/master/deeplearning1/nbs/lesson7.ipynb\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "m = Add()([dist2land_input, x])\n",
    "out = Activation('softmax')(m)\n",
    "\n",
    "\n",
    "model_with_distance = Model(inputs=[classifier_input, dist2land_input], outputs=out)\n",
    "model_with_distance.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 50, 50, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 25, 25, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 25, 25, 64)    18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 64)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 6, 6, 64)      0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 6, 6, 64)      36928       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 6, 6, 64)      256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 3, 3, 64)      0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 3, 3, 3)       1731        max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 3, 3, 3)       0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 3)             0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 3)             0           input_2[0][0]                    \n",
      "                                                                   global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 3)             0           add_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 132,099\n",
      "Trainable params: 131,715\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_distance.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 7s - loss: 0.3035 - acc: 0.8931 - val_loss: 0.3979 - val_acc: 0.8822\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1746 - acc: 0.9427 - val_loss: 0.2085 - val_acc: 0.9195\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1411 - acc: 0.9541 - val_loss: 0.2233 - val_acc: 0.9162\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1138 - acc: 0.9606 - val_loss: 0.6331 - val_acc: 0.8110\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1012 - acc: 0.9669 - val_loss: 0.1455 - val_acc: 0.9514\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0896 - acc: 0.9703 - val_loss: 0.1482 - val_acc: 0.9594\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0714 - acc: 0.9770 - val_loss: 0.2724 - val_acc: 0.9248\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0675 - acc: 0.9760 - val_loss: 0.2278 - val_acc: 0.9341\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0531 - acc: 0.9827 - val_loss: 0.2724 - val_acc: 0.9295\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0534 - acc: 0.9819 - val_loss: 0.1850 - val_acc: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca254678d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0229 - acc: 0.9924 - val_loss: 0.0826 - val_acc: 0.9794\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0705 - val_acc: 0.9834\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0772 - val_acc: 0.9814\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0100 - acc: 0.9971 - val_loss: 0.0836 - val_acc: 0.9807\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0861 - val_acc: 0.9814\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0940 - val_acc: 0.9774\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0880 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0909 - val_acc: 0.9767\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0916 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0899 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcac25497b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0931 - val_acc: 0.9807\n",
      "Epoch 2/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0916 - val_acc: 0.9794\n",
      "Epoch 3/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0947 - val_acc: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca24ec3ef0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout p = 0, Adam optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# # Following based on https://github.com/asmith26/courses/blob/master/deeplearning1/nbs/lesson7.ipynb\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "m = Add()([dist2land_input, x])\n",
    "out = Activation('softmax')(m)\n",
    "\n",
    "\n",
    "model_with_distance = Model(inputs=[classifier_input, dist2land_input], outputs=out)\n",
    "model_with_distance.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 7s - loss: 0.2414 - acc: 0.9113 - val_loss: 0.2038 - val_acc: 0.9301\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1270 - acc: 0.9559 - val_loss: 0.1139 - val_acc: 0.9587\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0964 - acc: 0.9659 - val_loss: 0.3751 - val_acc: 0.8696\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0849 - acc: 0.9716 - val_loss: 0.1530 - val_acc: 0.9448\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0671 - acc: 0.9773 - val_loss: 0.1388 - val_acc: 0.9514\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0587 - acc: 0.9806 - val_loss: 0.1036 - val_acc: 0.9661\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0520 - acc: 0.9826 - val_loss: 0.1304 - val_acc: 0.9587\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0427 - acc: 0.9835 - val_loss: 0.1378 - val_acc: 0.9508\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0363 - acc: 0.9872 - val_loss: 0.1093 - val_acc: 0.9674\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0404 - acc: 0.9853 - val_loss: 0.1194 - val_acc: 0.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca07a74ba8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0693 - val_acc: 0.9780\n",
      "Epoch 2/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0080 - acc: 0.9985 - val_loss: 0.0725 - val_acc: 0.9760\n",
      "Epoch 3/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0688 - val_acc: 0.9774\n",
      "Epoch 4/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0614 - val_acc: 0.9820\n",
      "Epoch 5/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca0797a828>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9820\n",
      "Epoch 2/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9827\n",
      "Epoch 3/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0659 - val_acc: 0.9820\n",
      "Epoch 4/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9827\n",
      "Epoch 5/5\n",
      "10188/10188 [==============================] - 6s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4f6b1cc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "K.set_value(model_with_distance.optimizer.lr, lr)\n",
    "\n",
    "model_with_distance.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout = 0.5, optimiser =Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# # Following based on https://github.com/asmith26/courses/blob/master/deeplearning1/nbs/lesson7.ipynb\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "m = Add()([dist2land_input, x])\n",
    "out = Activation('softmax')(m)\n",
    "\n",
    "\n",
    "model_with_adam_dropout = Model(inputs=[classifier_input, dist2land_input], outputs=out)\n",
    "model_with_adam_dropout.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 7s - loss: 0.2981 - acc: 0.8916 - val_loss: 0.3971 - val_acc: 0.8583\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1742 - acc: 0.9397 - val_loss: 0.2490 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1461 - acc: 0.9500 - val_loss: 0.1785 - val_acc: 0.9441\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1225 - acc: 0.9592 - val_loss: 0.1104 - val_acc: 0.9647\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1004 - acc: 0.9680 - val_loss: 0.1746 - val_acc: 0.9388\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0866 - acc: 0.9700 - val_loss: 0.2383 - val_acc: 0.9275\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0815 - acc: 0.9724 - val_loss: 0.3992 - val_acc: 0.8743\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0716 - acc: 0.9759 - val_loss: 0.1841 - val_acc: 0.9481\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0575 - acc: 0.9817 - val_loss: 0.0995 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0633 - acc: 0.9772 - val_loss: 0.1392 - val_acc: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca24e7ea58>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_with_adam_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0365 - acc: 0.9896 - val_loss: 0.0682 - val_acc: 0.9787\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0283 - acc: 0.9914 - val_loss: 0.0681 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0201 - acc: 0.9943 - val_loss: 0.0711 - val_acc: 0.9794\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0191 - acc: 0.9956 - val_loss: 0.0644 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0159 - acc: 0.9958 - val_loss: 0.0683 - val_acc: 0.9814\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0125 - acc: 0.9968 - val_loss: 0.0585 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0116 - acc: 0.9971 - val_loss: 0.0688 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0921 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0079 - acc: 0.9991 - val_loss: 0.0713 - val_acc: 0.9820\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0866 - val_acc: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4f6d3898>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_with_adam_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0705 - val_acc: 0.9834\n",
      "Epoch 2/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0697 - val_acc: 0.9847\n",
      "Epoch 3/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0715 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca06898320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "K.set_value(model_with_adam_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout = 0.2,0.5, optimiser =Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = 0.2\n",
    "p2 = 0.5\n",
    "\n",
    "classifier_input = Input(shape=input_shape)\n",
    "dist2land_input = Input(shape=(1,))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(classifier_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# # Following based on https://github.com/asmith26/courses/blob/master/deeplearning1/nbs/lesson7.ipynb\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Conv2D(64,(3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = MaxPooling2D()(x)   # REMOVED MAX POOLING FOR VISUALISATION\n",
    "x = Dropout(p1)(x)\n",
    "x = Conv2D(3,(3,3), padding='same')(x)\n",
    "x = Dropout(p2)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "m = Add()([dist2land_input, x])\n",
    "out = Activation('softmax')(m)\n",
    "\n",
    "\n",
    "model_with_adam_more_dropout = Model(inputs=[classifier_input, dist2land_input], outputs=out)\n",
    "model_with_adam_more_dropout.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 7s - loss: 0.3302 - acc: 0.8793 - val_loss: 0.2041 - val_acc: 0.9261\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1858 - acc: 0.9391 - val_loss: 0.1774 - val_acc: 0.9315\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1647 - acc: 0.9462 - val_loss: 0.1623 - val_acc: 0.9474\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1211 - acc: 0.9604 - val_loss: 0.3611 - val_acc: 0.8623\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.1112 - acc: 0.9618 - val_loss: 0.2414 - val_acc: 0.9228\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0980 - acc: 0.9666 - val_loss: 0.1478 - val_acc: 0.9448\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0909 - acc: 0.9694 - val_loss: 0.1673 - val_acc: 0.9514\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0765 - acc: 0.9748 - val_loss: 0.1692 - val_acc: 0.9501\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0771 - acc: 0.9749 - val_loss: 0.0858 - val_acc: 0.9741\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0641 - acc: 0.9790 - val_loss: 0.1928 - val_acc: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca061e4dd8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "K.set_value(model_with_adam_more_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_more_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0405 - acc: 0.9875 - val_loss: 0.0699 - val_acc: 0.9794\n",
      "Epoch 2/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0273 - acc: 0.9923 - val_loss: 0.0687 - val_acc: 0.9840\n",
      "Epoch 3/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0255 - acc: 0.9924 - val_loss: 0.0666 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0216 - acc: 0.9942 - val_loss: 0.0684 - val_acc: 0.9800\n",
      "Epoch 5/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0710 - val_acc: 0.9794\n",
      "Epoch 6/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0158 - acc: 0.9954 - val_loss: 0.0679 - val_acc: 0.9814\n",
      "Epoch 7/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0150 - acc: 0.9963 - val_loss: 0.0669 - val_acc: 0.9807\n",
      "Epoch 8/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0964 - val_acc: 0.9787\n",
      "Epoch 9/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0653 - val_acc: 0.9827\n",
      "Epoch 10/10\n",
      "10188/10188 [==============================] - 6s - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0616 - val_acc: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca06570e10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "K.set_value(model_with_adam_more_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_more_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10188 samples, validate on 1503 samples\n",
      "Epoch 1/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0742 - val_acc: 0.9820\n",
      "Epoch 2/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0726 - val_acc: 0.9814\n",
      "Epoch 3/3\n",
      "10188/10188 [==============================] - 6s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0709 - val_acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca053639e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "K.set_value(model_with_adam_more_dropout.optimizer.lr, lr)\n",
    "\n",
    "model_with_adam_more_dropout.fit([np_train_crops, np_train_feature], np_train_class,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=([np_valid_crops, np_valid_feature], np_valid_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_with_adam_more_dropout.save(trained_model_dir+'/1.1-as_mph-Python3_FCN_50x50_adam_more_dropout__full-png.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model_with_adam_more_dropout.to_json()\n",
    "\n",
    "with open(trained_model_dir+'/1.1-as_mph-Python3_FCN_50x50_adam_more_dropout__architecture_only-png.json', 'w') as outfile:\n",
    "    json.dump(model_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_with_adam_more_dropout.save_weights(trained_model_dir+'/1.1-as_mph-Python3_FCN_50x50_adam_more_dropout__weights_only-png.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
